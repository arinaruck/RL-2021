{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seminar_TRPO_pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arinaruck/RL-2021/blob/main/seminar_TRPO_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7XhrTHEkys1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec43b7ba-3079-4208-c1f1-7217977c879a"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    import os\n",
        "\n",
        "    os.system('apt-get install -y xvfb')\n",
        "    os.system('wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb -O ../xvfb')\n",
        "    os.system('apt-get install -y python-opengl ffmpeg')\n",
        "    os.system('pip install pyglet==1.2.4')\n",
        "\n",
        "# launch XVFB if you run on a server\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGkql_7_kys8"
      },
      "source": [
        "### Let's make a TRPO!\n",
        "\n",
        "In this notebook we will write the code of the one Trust Region Policy Optimization.\n",
        "As usually, it contains a few different parts which we are going to reproduce.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILM5yMoPkys9"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNfWcpCrkys-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05328848-0885-4f1c-ff9a-5d1a740aceae"
      },
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"Acrobot-v1\")\n",
        "env.reset()\n",
        "observation_shape = env.observation_space.shape\n",
        "n_actions = env.action_space.n\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Action Space\", env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Space Box(-28.274333953857422, 28.274333953857422, (6,), float32)\n",
            "Action Space Discrete(3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMMK5g2kytA",
        "outputId": "2316e3ae-afb9-46da-9c6c-d4d1a434183a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(env.render('rgb_array'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3c2dc56dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3c941cfe80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRWB909JkytA"
      },
      "source": [
        "### Step 1: Defining a network\n",
        "\n",
        "With all it's complexity, at it's core TRPO is yet another policy gradient method. \n",
        "\n",
        "This essentially means we're actually training a stochastic policy $ \\pi_\\theta(a|s) $. \n",
        "\n",
        "And yes, it's gonna be a neural network. So let's start by defining one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRgCyhhkytB"
      },
      "source": [
        "class TRPOAgent(nn.Module):\n",
        "    def __init__(self, state_shape, n_actions, hidden_size=32):\n",
        "        '''\n",
        "        Here you should define your model\n",
        "        You should have LOG-PROBABILITIES as output because you will need it to compute loss\n",
        "        We recommend that you start simple: \n",
        "        use 1-2 hidden layers with 100-500 units and relu for the first try\n",
        "        '''\n",
        "        nn.Module.__init__(self)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_shape[0], hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, n_actions),\n",
        "            nn.LogSoftmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, states):\n",
        "        \"\"\"\n",
        "        takes agent's observation (Variable), returns log-probabilities (Variable)\n",
        "        :param state_t: a batch of states, shape = [batch_size, state_shape]\n",
        "        \"\"\"\n",
        "\n",
        "        # Use your network to compute log_probs for given state\n",
        "        log_probs = self.model(states)\n",
        "        return log_probs\n",
        "\n",
        "    def get_log_probs(self, states):\n",
        "        '''\n",
        "        Log-probs for training\n",
        "        '''\n",
        "\n",
        "        return self.forward(states)\n",
        "\n",
        "    def get_probs(self, states):\n",
        "        '''\n",
        "        Probs for interaction\n",
        "        '''\n",
        "\n",
        "        return torch.exp(self.forward(states))\n",
        "\n",
        "    def act(self, obs, sample=True):\n",
        "        '''\n",
        "        Samples action from policy distribution (sample = True) or takes most likely action (sample = False)\n",
        "        :param: obs - single observation vector\n",
        "        :param sample: if True, samples from \\pi, otherwise takes most likely action\n",
        "        :returns: action (single integer) and probabilities for all actions\n",
        "        '''\n",
        "\n",
        "        probs = self.get_probs(Variable(torch.FloatTensor([obs]))).data.numpy()\n",
        "\n",
        "        if sample:\n",
        "            action = int(np.random.choice(n_actions, p=probs[0]))\n",
        "        else:\n",
        "            action = int(np.argmax(probs))\n",
        "\n",
        "        return action, probs[0]\n",
        "\n",
        "\n",
        "agent = TRPOAgent(observation_shape, n_actions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT2EUqbTkytC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1459db15-0dd7-4c90-f8a6-809d5c3ae4b3"
      },
      "source": [
        "# Check if log-probabilities satisfies all the requirements\n",
        "log_probs = agent.get_log_probs(Variable(torch.FloatTensor([env.reset()])))\n",
        "assert isinstance(\n",
        "    log_probs, Variable) and log_probs.requires_grad, \"qvalues must be a torch variable with grad\"\n",
        "assert len(\n",
        "    log_probs.shape) == 2 and log_probs.shape[0] == 1 and log_probs.shape[1] == n_actions\n",
        "sums = torch.sum(torch.exp(log_probs), dim=1)\n",
        "assert (0.999 < sums).all() and (1.001 > sums).all()\n",
        "\n",
        "# Demo use\n",
        "print(\"sampled:\", [agent.act(env.reset()) for _ in range(5)])\n",
        "print(\"greedy:\", [agent.act(env.reset(), sample=False) for _ in range(5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sampled: [(2, array([0.41918483, 0.2828254 , 0.29798982], dtype=float32)), (2, array([0.42795867, 0.2744813 , 0.29755998], dtype=float32)), (0, array([0.42604792, 0.27486852, 0.29908356], dtype=float32)), (0, array([0.42852578, 0.27145627, 0.30001795], dtype=float32)), (1, array([0.42753923, 0.27395415, 0.29850662], dtype=float32))]\n",
            "greedy: [(0, array([0.4281732 , 0.27344725, 0.2983795 ], dtype=float32)), (0, array([0.41964296, 0.28098816, 0.2993689 ], dtype=float32)), (0, array([0.42746574, 0.27310205, 0.2994322 ], dtype=float32)), (0, array([0.4182697 , 0.28115448, 0.30057585], dtype=float32)), (0, array([0.41678125, 0.2842559 , 0.29896286], dtype=float32))]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdwtiVGAkytD"
      },
      "source": [
        "#### Flat parameters operations\n",
        "\n",
        "We are going to use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzsJyjnjkytD"
      },
      "source": [
        "def get_flat_params_from(model):\n",
        "    params = []\n",
        "    for param in model.parameters():\n",
        "        params.append(param.data.view(-1))\n",
        "\n",
        "    flat_params = torch.cat(params)\n",
        "    return flat_params\n",
        "\n",
        "\n",
        "def set_flat_params_to(model, flat_params):\n",
        "    prev_ind = 0\n",
        "    for param in model.parameters():\n",
        "        flat_size = int(np.prod(list(param.size())))\n",
        "        param.data.copy_(\n",
        "            flat_params[prev_ind:prev_ind + flat_size].view(param.size()))\n",
        "        prev_ind += flat_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eITvSNBXkytE"
      },
      "source": [
        "Compute cummulative reward just like you did in vanilla REINFORCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOHhyxtHkytE"
      },
      "source": [
        "import scipy.signal\n",
        "\n",
        "\n",
        "def get_cummulative_returns(r, gamma=1):\n",
        "    \"\"\"\n",
        "    Computes cummulative discounted rewards given immediate rewards\n",
        "    G_i = r_i + gamma*r_{i+1} + gamma^2*r_{i+2} + ...\n",
        "    Also known as R(s,a).\n",
        "    \"\"\"\n",
        "    r = np.array(r)\n",
        "    assert r.ndim >= 1\n",
        "    return scipy.signal.lfilter([1], [1, -gamma], r[::-1], axis=0)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9u5BjbvkytF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff428fa2-a30b-47c9-edcf-10108146d655"
      },
      "source": [
        "# simple demo on rewards [0,0,1,0,0,1]\n",
        "get_cummulative_returns([0, 0, 1, 0, 0, 1], gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.40049, 1.5561 , 1.729  , 0.81   , 0.9    , 1.     ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK-hEBtzkytF"
      },
      "source": [
        "**Rollout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t0na1WwkytF"
      },
      "source": [
        "def rollout(env, agent, max_pathlength=2500, n_timesteps=50000):\n",
        "    \"\"\"\n",
        "    Generate rollouts for training.\n",
        "    :param: env - environment in which we will make actions to generate rollouts.\n",
        "    :param: act - the function that can return policy and action given observation.\n",
        "    :param: max_pathlength - maximum size of one path that we generate.\n",
        "    :param: n_timesteps - total sum of sizes of all pathes we generate.\n",
        "    \"\"\"\n",
        "    paths = []\n",
        "\n",
        "    total_timesteps = 0\n",
        "    while total_timesteps < n_timesteps:\n",
        "        obervations, actions, rewards, action_probs = [], [], [], []\n",
        "        obervation = env.reset()\n",
        "        for _ in range(max_pathlength):\n",
        "            action, policy = agent.act(obervation)\n",
        "            obervations.append(obervation)\n",
        "            actions.append(action)\n",
        "            action_probs.append(policy)\n",
        "            obervation, reward, done, _ = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            total_timesteps += 1\n",
        "            if done or total_timesteps == n_timesteps:\n",
        "                path = {\"observations\": np.array(obervations),\n",
        "                        \"policy\": np.array(action_probs),\n",
        "                        \"actions\": np.array(actions),\n",
        "                        \"rewards\": np.array(rewards),\n",
        "                        \"cumulative_returns\": get_cummulative_returns(rewards),\n",
        "                        }\n",
        "                paths.append(path)\n",
        "                break\n",
        "    return paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZSrr5G2kytG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff8f52d-6cc0-43ff-c57c-c5ed913de6b4"
      },
      "source": [
        "paths = rollout(env, agent, max_pathlength=5, n_timesteps=100)\n",
        "print(paths[-1])\n",
        "assert (paths[0]['policy'].shape == (5, n_actions))\n",
        "assert (paths[0]['cumulative_returns'].shape == (5,))\n",
        "assert (paths[0]['rewards'].shape == (5,))\n",
        "assert (paths[0]['observations'].shape == (5,)+observation_shape)\n",
        "assert (paths[0]['actions'].shape == (5,))\n",
        "print('It\\'s ok')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'observations': array([[ 0.99590277, -0.09043043,  0.99885812,  0.04777505,  0.02708692,\n",
            "        -0.01792332],\n",
            "       [ 0.99623677, -0.08667346,  0.99785208,  0.06550752,  0.010511  ,\n",
            "         0.19284797],\n",
            "       [ 0.99822787, -0.05950726,  0.99854927,  0.05384571,  0.25567456,\n",
            "        -0.30291818],\n",
            "       [ 0.9998728 , -0.01594928,  0.9997944 ,  0.02027696,  0.17051577,\n",
            "        -0.02077702],\n",
            "       [ 0.99947879,  0.0322822 ,  0.99979001, -0.02049238,  0.3006036 ,\n",
            "        -0.37205052]]), 'policy': array([[0.42416477, 0.2752243 , 0.30061096],\n",
            "       [0.4394077 , 0.25966743, 0.3009248 ],\n",
            "       [0.3967693 , 0.30467045, 0.2985603 ],\n",
            "       [0.42107815, 0.28020477, 0.29871708],\n",
            "       [0.3915732 , 0.31155467, 0.29687214]], dtype=float32), 'actions': array([2, 0, 2, 0, 2]), 'rewards': array([-1., -1., -1., -1., -1.]), 'cumulative_returns': array([-5., -4., -3., -2., -1.])}\n",
            "It's ok\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "718pVpdqkytH"
      },
      "source": [
        "### Step 3: Auxiliary functions\n",
        "\n",
        "Now let's define the loss functions and something else for actual TRPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPHtsXBpkytH"
      },
      "source": [
        "The surrogate reward should be\n",
        "$$J_{surr}= {1 \\over N} \\sum\\limits_{i=0}^N \\frac{\\pi_{\\theta}(s_i, a_i)}{\\pi_{\\theta_{old}}(s_i, a_i)}A_{\\theta_{old}(s_i, a_i)}$$\n",
        "\n",
        "For simplicity, let's use cummulative returns instead of advantage for now:\n",
        "$$J'_{surr}= {1 \\over N} \\sum\\limits_{i=0}^N \\frac{\\pi_{\\theta}(s_i, a_i)}{\\pi_{\\theta_{old}}(s_i, a_i)}G_{\\theta_{old}(s_i, a_i)}$$\n",
        "\n",
        "Or alternatively, minimize the surrogate loss:\n",
        "$$ L_{surr} = - J'_{surr} $$  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0NvFS55kytH"
      },
      "source": [
        "def get_loss(agent, observations, actions, cummulative_returns, old_probs):\n",
        "    \"\"\"\n",
        "    Computes TRPO objective\n",
        "    :param: observations - batch of observations\n",
        "    :param: actions - batch of actions\n",
        "    :param: cummulative_returns - batch of cummulative returns\n",
        "    :param: old_probs - batch of probabilities computed by old network\n",
        "    :returns: scalar value of the objective function\n",
        "    \"\"\"\n",
        "    batch_size = observations.shape[0]\n",
        "    log_probs_all = agent.get_log_probs(observations)\n",
        "    probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "    probs_for_actions = probs_all[torch.arange(\n",
        "        0, batch_size, out=torch.LongTensor()), actions]\n",
        "    old_probs_for_actions = old_probs[torch.arange(\n",
        "        0, batch_size, out=torch.LongTensor()), actions]\n",
        "\n",
        "    # Compute surrogate loss, aka importance-sampled policy gradient\n",
        "    Loss = -torch.mean((probs_for_actions / old_probs_for_actions) \n",
        "                        * cummulative_returns)\n",
        "\n",
        "    assert Loss.shape == torch.Size([])\n",
        "    return Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abQsLMa4kytI"
      },
      "source": [
        "We can ascend these gradients as long as our $pi_\\theta(a|s)$ satisfies the constraint\n",
        "$$E_{s,\\pi_{\\Theta_{t}}}\\Big[KL(\\pi(\\Theta_{t}, s) \\:||\\:\\pi(\\Theta_{t+1}, s))\\Big]< \\alpha$$\n",
        "\n",
        "\n",
        "where\n",
        "\n",
        "$$KL(p||q) = E _p log({p \\over q})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiFdP_3kytI"
      },
      "source": [
        "def get_kl(agent, observations, actions, cummulative_returns, old_probs):\n",
        "    \"\"\"\n",
        "    Computes KL-divergence between network policy and old policy\n",
        "    :param: observations - batch of observations\n",
        "    :param: actions - batch of actions\n",
        "    :param: cummulative_returns - batch of cummulative returns (we don't need it actually)\n",
        "    :param: old_probs - batch of probabilities computed by old network\n",
        "    :returns: scalar value of the KL-divergence\n",
        "    \"\"\"\n",
        "    batch_size = observations.shape[0]\n",
        "    log_probs_all = agent.get_log_probs(observations)\n",
        "    probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "    # Compute Kullback-Leibler divergence (see formula above)\n",
        "    # Note: you need to sum KL and entropy over all actions, not just the ones agent took\n",
        "    old_log_probs = torch.log(old_probs+1e-10)\n",
        "\n",
        "    kl = torch.sum(old_probs * (old_log_probs - log_probs_all)) / batch_size\n",
        "    assert kl.shape == torch.Size([])\n",
        "    assert (kl > -0.0001).all() and (kl < 10000).all()\n",
        "    return kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "859SAoc1kytJ"
      },
      "source": [
        "def get_entropy(agent, observations):\n",
        "    \"\"\"\n",
        "    Computes entropy of the network policy \n",
        "    :param: observations - batch of observations\n",
        "    :returns: scalar value of the entropy\n",
        "    \"\"\"\n",
        "\n",
        "    observations = Variable(torch.FloatTensor(observations))\n",
        "\n",
        "    batch_size = observations.shape[0]\n",
        "    log_probs_all = agent.get_log_probs(observations)\n",
        "    probs_all = torch.exp(log_probs_all)\n",
        "\n",
        "    entropy = torch.sum(-probs_all * log_probs_all) / batch_size\n",
        "\n",
        "    assert entropy.shape == torch.Size([])\n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY4IG7IukytJ"
      },
      "source": [
        "**Linear search**\n",
        "\n",
        "TRPO in its core involves ascending surrogate policy gradient constrained by KL divergence. \n",
        "\n",
        "In order to enforce this constraint, we're gonna use linesearch. You can find out more about it [here](https://en.wikipedia.org/wiki/Linear_search)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJOtzGawkytK"
      },
      "source": [
        "def linesearch(f, x, fullstep, max_kl):\n",
        "    \"\"\"\n",
        "    Linesearch finds the best parameters of neural networks in the direction of fullstep contrainted by KL divergence.\n",
        "    :param: f - function that returns loss, kl and arbitrary third component.\n",
        "    :param: x - old parameters of neural network.\n",
        "    :param: fullstep - direction in which we make search.\n",
        "    :param: max_kl - constraint of KL divergence.\n",
        "    :returns:\n",
        "    \"\"\"\n",
        "    max_backtracks = 10\n",
        "    loss, _, = f(x)\n",
        "    for stepfrac in .5**np.arange(max_backtracks):\n",
        "        xnew = x + stepfrac * fullstep\n",
        "        new_loss, kl = f(xnew)\n",
        "        actual_improve = new_loss - loss\n",
        "        if kl.data.numpy() <= max_kl and actual_improve.data.numpy() < 0:\n",
        "            x = xnew\n",
        "            loss = new_loss\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLlGlZF9kytK"
      },
      "source": [
        "**Conjugate gradients**\n",
        "\n",
        "Since TRPO includes contrainted optimization, we will need to solve Ax=b using conjugate gradients.\n",
        "\n",
        "In general, CG is an algorithm that solves Ax=b where A is positive-defined. A is Hessian matrix so A is positive-defined. You can find out more about them [here](https://en.wikipedia.org/wiki/Conjugate_gradient_method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd4M-PMlkytK"
      },
      "source": [
        "from numpy.linalg import inv\n",
        "\n",
        "\n",
        "def conjugate_gradient(f_Ax, b, cg_iters=10, residual_tol=1e-10):\n",
        "    \"\"\"\n",
        "    This method solves system of equation Ax=b using iterative method called conjugate gradients\n",
        "    :f_Ax: function that returns Ax\n",
        "    :b: targets for Ax\n",
        "    :cg_iters: how many iterations this method should do\n",
        "    :residual_tol: epsilon for stability\n",
        "    \"\"\"\n",
        "    p = b.clone()\n",
        "    r = b.clone()\n",
        "    x = torch.zeros(b.size())\n",
        "    rdotr = torch.sum(r*r)\n",
        "    for i in range(cg_iters):\n",
        "        z = f_Ax(p)\n",
        "        v = rdotr / (torch.sum(p*z) + 1e-8)\n",
        "        x += v * p\n",
        "        r -= v * z\n",
        "        newrdotr = torch.sum(r*r)\n",
        "        mu = newrdotr / (rdotr + 1e-8)\n",
        "        p = r + mu * p\n",
        "        rdotr = newrdotr\n",
        "        if rdotr < residual_tol:\n",
        "            break\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoX9cbM3kytL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9452b700-b5e7-4c86-952b-d28e667f08ac"
      },
      "source": [
        "# This code validates conjugate gradients\n",
        "A = np.random.rand(8, 8)\n",
        "A = np.matmul(np.transpose(A), A)\n",
        "\n",
        "\n",
        "def f_Ax(x):\n",
        "    return torch.matmul(torch.FloatTensor(A), x.view((-1, 1))).view(-1)\n",
        "\n",
        "\n",
        "b = np.random.rand(8)\n",
        "\n",
        "w = np.matmul(np.matmul(inv(np.matmul(np.transpose(A), A)),\n",
        "                        np.transpose(A)), b.reshape((-1, 1))).reshape(-1)\n",
        "print(w)\n",
        "print(conjugate_gradient(f_Ax, torch.FloatTensor(b)).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -8.99114847  25.26165065 -18.69398177   5.79440789 -24.80590949\n",
            "   3.97137373  20.36369485   1.11541522]\n",
            "[ -8.990553   25.244747  -18.689121    5.7855883 -24.793926    3.9575248\n",
            "  20.37142     1.1110415]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqlGzgeVkytL"
      },
      "source": [
        "### Step 4: training\n",
        "In this section we construct the whole update step function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D8wfOAckytL"
      },
      "source": [
        "def update_step(agent, observations, actions, cummulative_returns, old_probs, max_kl):\n",
        "    \"\"\"\n",
        "    This function does the TRPO update step\n",
        "    :param: observations - batch of observations\n",
        "    :param: actions - batch of actions\n",
        "    :param: cummulative_returns - batch of cummulative returns\n",
        "    :param: old_probs - batch of probabilities computed by old network\n",
        "    :param: max_kl - controls how big KL divergence may be between old and new policy every step.\n",
        "    :returns: KL between new and old policies and the value of the loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    # Here we prepare the information\n",
        "    observations = Variable(torch.FloatTensor(observations))\n",
        "    actions = torch.LongTensor(actions)\n",
        "    cummulative_returns = Variable(torch.FloatTensor(cummulative_returns))\n",
        "    old_probs = Variable(torch.FloatTensor(old_probs))\n",
        "\n",
        "    # Here we compute gradient of the loss function\n",
        "    loss = get_loss(agent, observations, actions,\n",
        "                    cummulative_returns, old_probs)\n",
        "    grads = torch.autograd.grad(loss, agent.parameters())\n",
        "    loss_grad = torch.cat([grad.view(-1) for grad in grads]).data\n",
        "\n",
        "    def Fvp(v):\n",
        "        # Here we compute Fx to do solve Fx = g using conjugate gradients\n",
        "        # We actually do here a couple of tricks to compute it efficiently\n",
        "\n",
        "        kl = get_kl(agent, observations, actions,\n",
        "                    cummulative_returns, old_probs)\n",
        "\n",
        "        grads = torch.autograd.grad(kl, agent.parameters(), create_graph=True)\n",
        "        flat_grad_kl = torch.cat([grad.view(-1) for grad in grads])\n",
        "\n",
        "        kl_v = (flat_grad_kl * Variable(v)).sum()\n",
        "        grads = torch.autograd.grad(kl_v, agent.parameters())\n",
        "        flat_grad_grad_kl = torch.cat(\n",
        "            [grad.contiguous().view(-1) for grad in grads]).data\n",
        "\n",
        "        return flat_grad_grad_kl + v * 0.1\n",
        "\n",
        "    # Here we solveolve Fx = g system using conjugate gradients\n",
        "    stepdir = conjugate_gradient(Fvp, -loss_grad, 10)\n",
        "\n",
        "    # Here we compute the initial vector to do linear search\n",
        "    shs = 0.5 * (stepdir * Fvp(stepdir)).sum(0, keepdim=True)\n",
        "\n",
        "    lm = torch.sqrt(shs / max_kl)\n",
        "    fullstep = stepdir / lm[0]\n",
        "\n",
        "    neggdotstepdir = (-loss_grad * stepdir).sum(0, keepdim=True)\n",
        "\n",
        "    # Here we get the start point\n",
        "    prev_params = get_flat_params_from(agent)\n",
        "\n",
        "    def get_loss_kl(params):\n",
        "        # Helper for linear search\n",
        "        set_flat_params_to(agent, params)\n",
        "        return [get_loss(agent, observations, actions, cummulative_returns, old_probs),\n",
        "                get_kl(agent, observations, actions, cummulative_returns, old_probs)]\n",
        "\n",
        "    # Here we find our new parameters\n",
        "    new_params = linesearch(get_loss_kl, prev_params, fullstep, max_kl)\n",
        "\n",
        "    # And we set it to our network\n",
        "    set_flat_params_to(agent, new_params)\n",
        "\n",
        "    return get_loss_kl(new_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsaAgIqZkytM"
      },
      "source": [
        "##### Step 5: Main TRPO loop\n",
        "\n",
        "Here we will train our network!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCqSbRjmkytM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa45da6-beaa-4c37-a6b8-59eb46c8f397"
      },
      "source": [
        "import time\n",
        "from itertools import count\n",
        "from collections import OrderedDict\n",
        "\n",
        "# this is hyperparameter of TRPO. It controls how big KL divergence may be between old and new policy every step.\n",
        "max_kl = 0.01\n",
        "numeptotal = 0  # this is number of episodes that we played.\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in count(1):\n",
        "\n",
        "    print(\"\\n********** Iteration %i ************\" % i)\n",
        "\n",
        "    # Generating paths.\n",
        "    print(\"Rollout\")\n",
        "    paths = rollout(env, agent)\n",
        "    print(\"Made rollout\")\n",
        "\n",
        "    # Updating policy.\n",
        "    observations = np.concatenate([path[\"observations\"] for path in paths])\n",
        "    actions = np.concatenate([path[\"actions\"] for path in paths])\n",
        "    returns = np.concatenate([path[\"cumulative_returns\"] for path in paths])\n",
        "    old_probs = np.concatenate([path[\"policy\"] for path in paths])\n",
        "\n",
        "    loss, kl = update_step(agent, observations, actions,\n",
        "                           returns, old_probs, max_kl)\n",
        "\n",
        "    # Report current progress\n",
        "    episode_rewards = np.array([path[\"rewards\"].sum() for path in paths])\n",
        "\n",
        "    stats = OrderedDict()\n",
        "    numeptotal += len(episode_rewards)\n",
        "    stats[\"Total number of episodes\"] = numeptotal\n",
        "    stats[\"Average sum of rewards per episode\"] = episode_rewards.mean()\n",
        "    stats[\"Std of rewards per episode\"] = episode_rewards.std()\n",
        "    stats[\"Time elapsed\"] = \"%.2f mins\" % ((time.time() - start_time)/60.)\n",
        "    stats[\"KL between old and new distribution\"] = kl.data.numpy()\n",
        "    stats[\"Entropy\"] = get_entropy(agent, observations).data.numpy()\n",
        "    stats[\"Surrogate loss\"] = loss.data.numpy()\n",
        "    for k, v in stats.items():\n",
        "        print(k + \": \" + \" \" * (40 - len(k)) + str(v))\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "********** Iteration 1 ************\n",
            "Rollout\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py:119: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "KL between old and new distribution:      0.009989268\n",
            "Entropy:                                  0.07615041\n",
            "Surrogate loss:                           45.53017\n",
            "\n",
            "********** Iteration 48 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 23613\n",
            "Average sum of rewards per episode:       -85.81076388888889\n",
            "Std of rewards per episode:               35.74000378077494\n",
            "Time elapsed:                             16.82 mins\n",
            "KL between old and new distribution:      0.009986952\n",
            "Entropy:                                  0.06461163\n",
            "Surrogate loss:                           50.15389\n",
            "\n",
            "********** Iteration 49 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 24205\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               22.64961914313914\n",
            "Time elapsed:                             17.17 mins\n",
            "KL between old and new distribution:      0.009987379\n",
            "Entropy:                                  0.06559232\n",
            "Surrogate loss:                           44.718857\n",
            "\n",
            "********** Iteration 50 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 24785\n",
            "Average sum of rewards per episode:       -85.20862068965518\n",
            "Std of rewards per episode:               21.948833795763605\n",
            "Time elapsed:                             17.52 mins\n",
            "KL between old and new distribution:      0.009989888\n",
            "Entropy:                                  0.07709208\n",
            "Surrogate loss:                           45.25592\n",
            "\n",
            "********** Iteration 51 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 25375\n",
            "Average sum of rewards per episode:       -83.74915254237288\n",
            "Std of rewards per episode:               26.44562296218576\n",
            "Time elapsed:                             17.87 mins\n",
            "KL between old and new distribution:      0.009988114\n",
            "Entropy:                                  0.07445077\n",
            "Surrogate loss:                           45.90467\n",
            "\n",
            "********** Iteration 52 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 25965\n",
            "Average sum of rewards per episode:       -83.74915254237288\n",
            "Std of rewards per episode:               25.938351769188312\n",
            "Time elapsed:                             18.22 mins\n",
            "KL between old and new distribution:      0.00997328\n",
            "Entropy:                                  0.070418894\n",
            "Surrogate loss:                           45.756756\n",
            "\n",
            "********** Iteration 53 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 26560\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               20.81597071188852\n",
            "Time elapsed:                             18.57 mins\n",
            "KL between old and new distribution:      0.009995481\n",
            "Entropy:                                  0.07947338\n",
            "Surrogate loss:                           44.00819\n",
            "\n",
            "********** Iteration 54 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 27144\n",
            "Average sum of rewards per episode:       -84.62157534246575\n",
            "Std of rewards per episode:               30.94585882376209\n",
            "Time elapsed:                             18.91 mins\n",
            "KL between old and new distribution:      0.009978462\n",
            "Entropy:                                  0.072519794\n",
            "Surrogate loss:                           47.78816\n",
            "\n",
            "********** Iteration 55 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 27730\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               24.315501092972962\n",
            "Time elapsed:                             19.26 mins\n",
            "KL between old and new distribution:      0.009998636\n",
            "Entropy:                                  0.07203206\n",
            "Surrogate loss:                           45.590355\n",
            "\n",
            "********** Iteration 56 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 28301\n",
            "Average sum of rewards per episode:       -86.56917688266199\n",
            "Std of rewards per episode:               30.882297807747417\n",
            "Time elapsed:                             19.61 mins\n",
            "KL between old and new distribution:      0.00997829\n",
            "Entropy:                                  0.06596764\n",
            "Surrogate loss:                           48.622215\n",
            "\n",
            "********** Iteration 57 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 28889\n",
            "Average sum of rewards per episode:       -84.03571428571429\n",
            "Std of rewards per episode:               21.27757314750954\n",
            "Time elapsed:                             19.96 mins\n",
            "KL between old and new distribution:      0.009983466\n",
            "Entropy:                                  0.05880421\n",
            "Surrogate loss:                           44.59088\n",
            "\n",
            "********** Iteration 58 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 29462\n",
            "Average sum of rewards per episode:       -86.26527050610821\n",
            "Std of rewards per episode:               33.10224466543284\n",
            "Time elapsed:                             20.31 mins\n",
            "KL between old and new distribution:      0.009998266\n",
            "Entropy:                                  0.062510476\n",
            "Surrogate loss:                           49.29288\n",
            "\n",
            "********** Iteration 59 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 30069\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               14.116957259247375\n",
            "Time elapsed:                             20.66 mins\n",
            "KL between old and new distribution:      0.007873024\n",
            "Entropy:                                  0.05181616\n",
            "Surrogate loss:                           41.838997\n",
            "\n",
            "********** Iteration 60 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 30662\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               20.85826101710355\n",
            "Time elapsed:                             21.01 mins\n",
            "KL between old and new distribution:      0.009988664\n",
            "Entropy:                                  0.052617345\n",
            "Surrogate loss:                           44.14106\n",
            "\n",
            "********** Iteration 61 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 31256\n",
            "Average sum of rewards per episode:       -83.17845117845118\n",
            "Std of rewards per episode:               26.068515143295677\n",
            "Time elapsed:                             21.36 mins\n",
            "KL between old and new distribution:      0.0099952025\n",
            "Entropy:                                  0.047351964\n",
            "Surrogate loss:                           45.553295\n",
            "\n",
            "********** Iteration 62 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 31850\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               22.277725108653556\n",
            "Time elapsed:                             21.71 mins\n",
            "KL between old and new distribution:      0.009993185\n",
            "Entropy:                                  0.048633404\n",
            "Surrogate loss:                           44.451553\n",
            "\n",
            "********** Iteration 63 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 32454\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               18.242506751087802\n",
            "Time elapsed:                             22.06 mins\n",
            "KL between old and new distribution:      0.009992355\n",
            "Entropy:                                  0.051699046\n",
            "Surrogate loss:                           42.757946\n",
            "\n",
            "********** Iteration 64 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 33045\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               20.33556686245237\n",
            "Time elapsed:                             22.41 mins\n",
            "KL between old and new distribution:      0.0098695615\n",
            "Entropy:                                  0.038677465\n",
            "Surrogate loss:                           44.2026\n",
            "\n",
            "********** Iteration 65 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 33635\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               22.471577950162697\n",
            "Time elapsed:                             22.76 mins\n",
            "KL between old and new distribution:      0.009973008\n",
            "Entropy:                                  0.03939865\n",
            "Surrogate loss:                           44.79042\n",
            "\n",
            "********** Iteration 66 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 34231\n",
            "Average sum of rewards per episode:       -82.89597315436242\n",
            "Std of rewards per episode:               23.693709354576484\n",
            "Time elapsed:                             23.11 mins\n",
            "KL between old and new distribution:      0.009982803\n",
            "Entropy:                                  0.037808757\n",
            "Surrogate loss:                           44.73547\n",
            "\n",
            "********** Iteration 67 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 34830\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               15.63542000681186\n",
            "Time elapsed:                             23.47 mins\n",
            "KL between old and new distribution:      0.009993167\n",
            "Entropy:                                  0.037475772\n",
            "Surrogate loss:                           42.62858\n",
            "\n",
            "********** Iteration 68 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 35410\n",
            "Average sum of rewards per episode:       -85.21034482758621\n",
            "Std of rewards per episode:               27.267902626975136\n",
            "Time elapsed:                             23.82 mins\n",
            "KL between old and new distribution:      0.009994625\n",
            "Entropy:                                  0.033239774\n",
            "Surrogate loss:                           46.830456\n",
            "\n",
            "********** Iteration 69 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 35999\n",
            "Average sum of rewards per episode:       -83.893039049236\n",
            "Std of rewards per episode:               27.032152818640984\n",
            "Time elapsed:                             24.17 mins\n",
            "KL between old and new distribution:      0.009990436\n",
            "Entropy:                                  0.03292487\n",
            "Surrogate loss:                           46.15809\n",
            "\n",
            "********** Iteration 70 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 36588\n",
            "Average sum of rewards per episode:       -83.89134125636673\n",
            "Std of rewards per episode:               20.55697477629317\n",
            "Time elapsed:                             24.52 mins\n",
            "KL between old and new distribution:      0.00999328\n",
            "Entropy:                                  0.035323188\n",
            "Surrogate loss:                           44.34978\n",
            "\n",
            "********** Iteration 71 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 37174\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               23.969290140779748\n",
            "Time elapsed:                             24.87 mins\n",
            "KL between old and new distribution:      0.009974209\n",
            "Entropy:                                  0.031535305\n",
            "Surrogate loss:                           45.39034\n",
            "\n",
            "********** Iteration 72 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 37764\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               21.51559825132946\n",
            "Time elapsed:                             25.22 mins\n",
            "KL between old and new distribution:      0.0066053877\n",
            "Entropy:                                  0.030754946\n",
            "Surrogate loss:                           44.579636\n",
            "\n",
            "********** Iteration 73 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 38331\n",
            "Average sum of rewards per episode:       -87.18342151675485\n",
            "Std of rewards per episode:               26.246387982356424\n",
            "Time elapsed:                             25.58 mins\n",
            "KL between old and new distribution:      0.009979341\n",
            "Entropy:                                  0.03243646\n",
            "Surrogate loss:                           47.369083\n",
            "\n",
            "********** Iteration 74 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 38922\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               23.527330482170537\n",
            "Time elapsed:                             25.93 mins\n",
            "KL between old and new distribution:      0.009996853\n",
            "Entropy:                                  0.029575273\n",
            "Surrogate loss:                           44.96863\n",
            "\n",
            "********** Iteration 75 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 39511\n",
            "Average sum of rewards per episode:       -83.89134125636673\n",
            "Std of rewards per episode:               18.809790728056743\n",
            "Time elapsed:                             26.28 mins\n",
            "KL between old and new distribution:      0.009983054\n",
            "Entropy:                                  0.036050204\n",
            "Surrogate loss:                           43.92119\n",
            "\n",
            "********** Iteration 76 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 40106\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               25.649452843759423\n",
            "Time elapsed:                             26.63 mins\n",
            "KL between old and new distribution:      0.009975077\n",
            "Entropy:                                  0.033255946\n",
            "Surrogate loss:                           45.285194\n",
            "\n",
            "********** Iteration 77 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 40699\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               19.727603786063707\n",
            "Time elapsed:                             26.98 mins\n",
            "KL between old and new distribution:      0.009987894\n",
            "Entropy:                                  0.03523872\n",
            "Surrogate loss:                           43.87735\n",
            "\n",
            "********** Iteration 78 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 41297\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               19.044735557077466\n",
            "Time elapsed:                             27.33 mins\n",
            "KL between old and new distribution:      0.009981447\n",
            "Entropy:                                  0.0332231\n",
            "Surrogate loss:                           43.38058\n",
            "\n",
            "********** Iteration 79 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 41898\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               17.09281854566027\n",
            "Time elapsed:                             27.68 mins\n",
            "KL between old and new distribution:      0.009975905\n",
            "Entropy:                                  0.04017878\n",
            "Surrogate loss:                           42.793945\n",
            "\n",
            "********** Iteration 80 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 42493\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               16.794169597706222\n",
            "Time elapsed:                             28.03 mins\n",
            "KL between old and new distribution:      0.009125242\n",
            "Entropy:                                  0.034659505\n",
            "Surrogate loss:                           43.16576\n",
            "\n",
            "********** Iteration 81 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 43084\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               20.515494959283274\n",
            "Time elapsed:                             28.38 mins\n",
            "KL between old and new distribution:      0.0099943355\n",
            "Entropy:                                  0.039830655\n",
            "Surrogate loss:                           44.238335\n",
            "\n",
            "********** Iteration 82 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 43677\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               17.33990913896818\n",
            "Time elapsed:                             28.73 mins\n",
            "KL between old and new distribution:      0.009992538\n",
            "Entropy:                                  0.03262767\n",
            "Surrogate loss:                           43.28794\n",
            "\n",
            "********** Iteration 83 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 44255\n",
            "Average sum of rewards per episode:       -85.50692041522491\n",
            "Std of rewards per episode:               25.702734775607507\n",
            "Time elapsed:                             29.08 mins\n",
            "KL between old and new distribution:      0.009982865\n",
            "Entropy:                                  0.045004766\n",
            "Surrogate loss:                           46.357174\n",
            "\n",
            "********** Iteration 84 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 44853\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               17.868703959760275\n",
            "Time elapsed:                             29.43 mins\n",
            "KL between old and new distribution:      0.009992459\n",
            "Entropy:                                  0.036216024\n",
            "Surrogate loss:                           43.15557\n",
            "\n",
            "********** Iteration 85 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 45424\n",
            "Average sum of rewards per episode:       -86.56917688266199\n",
            "Std of rewards per episode:               28.72650239069644\n",
            "Time elapsed:                             29.77 mins\n",
            "KL between old and new distribution:      0.009999138\n",
            "Entropy:                                  0.036377847\n",
            "Surrogate loss:                           47.895115\n",
            "\n",
            "********** Iteration 86 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 46004\n",
            "Average sum of rewards per episode:       -85.21034482758621\n",
            "Std of rewards per episode:               29.49138792851329\n",
            "Time elapsed:                             30.12 mins\n",
            "KL between old and new distribution:      0.00902344\n",
            "Entropy:                                  0.035328206\n",
            "Surrogate loss:                           47.60521\n",
            "\n",
            "********** Iteration 87 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 46606\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               15.17182676659866\n",
            "Time elapsed:                             30.48 mins\n",
            "KL between old and new distribution:      0.009984736\n",
            "Entropy:                                  0.03590833\n",
            "Surrogate loss:                           42.358887\n",
            "\n",
            "********** Iteration 88 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 47200\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               16.16010172828701\n",
            "Time elapsed:                             30.83 mins\n",
            "KL between old and new distribution:      0.009980919\n",
            "Entropy:                                  0.031765416\n",
            "Surrogate loss:                           43.09107\n",
            "\n",
            "********** Iteration 89 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 47797\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               16.62840519503153\n",
            "Time elapsed:                             31.18 mins\n",
            "KL between old and new distribution:      0.0099979155\n",
            "Entropy:                                  0.029169358\n",
            "Surrogate loss:                           42.96687\n",
            "\n",
            "********** Iteration 90 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 48393\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               19.840992944242178\n",
            "Time elapsed:                             31.53 mins\n",
            "KL between old and new distribution:      0.009994115\n",
            "Entropy:                                  0.03808273\n",
            "Surrogate loss:                           43.641327\n",
            "\n",
            "********** Iteration 91 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 48987\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               22.31849497244191\n",
            "Time elapsed:                             31.88 mins\n",
            "KL between old and new distribution:      0.00998714\n",
            "Entropy:                                  0.03829188\n",
            "Surrogate loss:                           44.48268\n",
            "\n",
            "********** Iteration 92 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 49568\n",
            "Average sum of rewards per episode:       -85.06196213425129\n",
            "Std of rewards per episode:               28.444763919372907\n",
            "Time elapsed:                             32.23 mins\n",
            "KL between old and new distribution:      0.0099785905\n",
            "Entropy:                                  0.04592232\n",
            "Surrogate loss:                           47.11018\n",
            "\n",
            "********** Iteration 93 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 50160\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               20.876450686723565\n",
            "Time elapsed:                             32.58 mins\n",
            "KL between old and new distribution:      0.009991296\n",
            "Entropy:                                  0.04853253\n",
            "Surrogate loss:                           44.256115\n",
            "\n",
            "********** Iteration 94 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 50756\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               20.324892192191477\n",
            "Time elapsed:                             32.93 mins\n",
            "KL between old and new distribution:      0.009976927\n",
            "Entropy:                                  0.06875794\n",
            "Surrogate loss:                           43.78931\n",
            "\n",
            "********** Iteration 95 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 51346\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               24.838303224972154\n",
            "Time elapsed:                             33.28 mins\n",
            "KL between old and new distribution:      0.009985235\n",
            "Entropy:                                  0.0835131\n",
            "Surrogate loss:                           45.37588\n",
            "\n",
            "********** Iteration 96 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 51946\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               16.635888163846257\n",
            "Time elapsed:                             33.63 mins\n",
            "KL between old and new distribution:      0.009998075\n",
            "Entropy:                                  0.07166514\n",
            "Surrogate loss:                           42.752975\n",
            "\n",
            "********** Iteration 97 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 52532\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               21.42694333239356\n",
            "Time elapsed:                             33.98 mins\n",
            "KL between old and new distribution:      0.009997581\n",
            "Entropy:                                  0.10174984\n",
            "Surrogate loss:                           44.67767\n",
            "\n",
            "********** Iteration 98 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 53117\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               24.01174159417165\n",
            "Time elapsed:                             34.33 mins\n",
            "KL between old and new distribution:      0.0099857105\n",
            "Entropy:                                  0.08326791\n",
            "Surrogate loss:                           45.44292\n",
            "\n",
            "********** Iteration 99 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 53707\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               23.973904286884085\n",
            "Time elapsed:                             34.68 mins\n",
            "KL between old and new distribution:      0.009988539\n",
            "Entropy:                                  0.083770566\n",
            "Surrogate loss:                           45.19787\n",
            "\n",
            "********** Iteration 100 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 54300\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               24.603868758495633\n",
            "Time elapsed:                             35.04 mins\n",
            "KL between old and new distribution:      0.0099773\n",
            "Entropy:                                  0.08915819\n",
            "Surrogate loss:                           45.13694\n",
            "\n",
            "********** Iteration 101 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 54892\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               18.380232589169204\n",
            "Time elapsed:                             35.39 mins\n",
            "KL between old and new distribution:      0.009980681\n",
            "Entropy:                                  0.1013764\n",
            "Surrogate loss:                           43.52996\n",
            "\n",
            "********** Iteration 102 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 55486\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               17.516343469513995\n",
            "Time elapsed:                             35.74 mins\n",
            "KL between old and new distribution:      0.009990965\n",
            "Entropy:                                  0.1278495\n",
            "Surrogate loss:                           43.337746\n",
            "\n",
            "********** Iteration 103 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 56071\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               22.17058128593414\n",
            "Time elapsed:                             36.09 mins\n",
            "KL between old and new distribution:      0.009981544\n",
            "Entropy:                                  0.11296911\n",
            "Surrogate loss:                           45.05474\n",
            "\n",
            "********** Iteration 104 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 56647\n",
            "Average sum of rewards per episode:       -85.80729166666667\n",
            "Std of rewards per episode:               23.61561429432366\n",
            "Time elapsed:                             36.44 mins\n",
            "KL between old and new distribution:      0.009999021\n",
            "Entropy:                                  0.11116334\n",
            "Surrogate loss:                           46.022865\n",
            "\n",
            "********** Iteration 105 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 57225\n",
            "Average sum of rewards per episode:       -85.50692041522491\n",
            "Std of rewards per episode:               27.148205071662534\n",
            "Time elapsed:                             36.80 mins\n",
            "KL between old and new distribution:      0.009994832\n",
            "Entropy:                                  0.11168352\n",
            "Surrogate loss:                           46.93278\n",
            "\n",
            "********** Iteration 106 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 57811\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               25.898553260349527\n",
            "Time elapsed:                             37.15 mins\n",
            "KL between old and new distribution:      0.009998949\n",
            "Entropy:                                  0.11159989\n",
            "Surrogate loss:                           45.93581\n",
            "\n",
            "********** Iteration 107 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 58403\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               24.43597212749559\n",
            "Time elapsed:                             37.50 mins\n",
            "KL between old and new distribution:      0.009991369\n",
            "Entropy:                                  0.09404101\n",
            "Surrogate loss:                           45.17036\n",
            "\n",
            "********** Iteration 108 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 58991\n",
            "Average sum of rewards per episode:       -84.03401360544218\n",
            "Std of rewards per episode:               24.8893920430356\n",
            "Time elapsed:                             37.86 mins\n",
            "KL between old and new distribution:      0.009992429\n",
            "Entropy:                                  0.10743521\n",
            "Surrogate loss:                           45.584396\n",
            "\n",
            "********** Iteration 109 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 59578\n",
            "Average sum of rewards per episode:       -84.18057921635435\n",
            "Std of rewards per episode:               23.571879219827096\n",
            "Time elapsed:                             38.21 mins\n",
            "KL between old and new distribution:      0.00997505\n",
            "Entropy:                                  0.10717111\n",
            "Surrogate loss:                           45.237717\n",
            "\n",
            "********** Iteration 110 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 60169\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               21.294301894019675\n",
            "Time elapsed:                             38.56 mins\n",
            "KL between old and new distribution:      0.009999455\n",
            "Entropy:                                  0.09564265\n",
            "Surrogate loss:                           44.393517\n",
            "\n",
            "********** Iteration 111 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 60766\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               20.88698167241387\n",
            "Time elapsed:                             38.91 mins\n",
            "KL between old and new distribution:      0.009991005\n",
            "Entropy:                                  0.087972306\n",
            "Surrogate loss:                           43.8372\n",
            "\n",
            "********** Iteration 112 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 61367\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               20.134193395112852\n",
            "Time elapsed:                             39.26 mins\n",
            "KL between old and new distribution:      0.009989286\n",
            "Entropy:                                  0.094289914\n",
            "Surrogate loss:                           43.45058\n",
            "\n",
            "********** Iteration 113 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 61954\n",
            "Average sum of rewards per episode:       -84.18228279386712\n",
            "Std of rewards per episode:               27.123149517769843\n",
            "Time elapsed:                             39.62 mins\n",
            "KL between old and new distribution:      0.009986426\n",
            "Entropy:                                  0.08121683\n",
            "Surrogate loss:                           46.29036\n",
            "\n",
            "********** Iteration 114 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 62556\n",
            "Average sum of rewards per episode:       -82.05980066445183\n",
            "Std of rewards per episode:               23.721174049762713\n",
            "Time elapsed:                             39.97 mins\n",
            "KL between old and new distribution:      0.009995299\n",
            "Entropy:                                  0.079689294\n",
            "Surrogate loss:                           44.31277\n",
            "\n",
            "********** Iteration 115 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 63148\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               20.228721988183064\n",
            "Time elapsed:                             40.33 mins\n",
            "KL between old and new distribution:      0.009978157\n",
            "Entropy:                                  0.07065441\n",
            "Surrogate loss:                           44.097527\n",
            "\n",
            "********** Iteration 116 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 63747\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               18.549457822281433\n",
            "Time elapsed:                             40.68 mins\n",
            "KL between old and new distribution:      0.009972336\n",
            "Entropy:                                  0.07891994\n",
            "Surrogate loss:                           43.20934\n",
            "\n",
            "********** Iteration 117 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 64356\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               17.97245122090247\n",
            "Time elapsed:                             41.03 mins\n",
            "KL between old and new distribution:      0.009988728\n",
            "Entropy:                                  0.075947195\n",
            "Surrogate loss:                           42.43968\n",
            "\n",
            "********** Iteration 118 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 64960\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               16.884423429606326\n",
            "Time elapsed:                             41.39 mins\n",
            "KL between old and new distribution:      0.009982876\n",
            "Entropy:                                  0.0698924\n",
            "Surrogate loss:                           42.48754\n",
            "\n",
            "********** Iteration 119 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 65552\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               21.35586137098718\n",
            "Time elapsed:                             41.74 mins\n",
            "KL between old and new distribution:      0.009972915\n",
            "Entropy:                                  0.06282077\n",
            "Surrogate loss:                           44.330864\n",
            "\n",
            "********** Iteration 120 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 66149\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               21.851516742626064\n",
            "Time elapsed:                             42.09 mins\n",
            "KL between old and new distribution:      0.009981993\n",
            "Entropy:                                  0.050031934\n",
            "Surrogate loss:                           44.15336\n",
            "\n",
            "********** Iteration 121 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 66744\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               25.893485328258585\n",
            "Time elapsed:                             42.45 mins\n",
            "KL between old and new distribution:      0.009978528\n",
            "Entropy:                                  0.04609239\n",
            "Surrogate loss:                           45.44853\n",
            "\n",
            "********** Iteration 122 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 67334\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               24.950438031087145\n",
            "Time elapsed:                             42.80 mins\n",
            "KL between old and new distribution:      0.008400589\n",
            "Entropy:                                  0.046873208\n",
            "Surrogate loss:                           45.485096\n",
            "\n",
            "********** Iteration 123 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 67911\n",
            "Average sum of rewards per episode:       -85.66031195840554\n",
            "Std of rewards per episode:               34.92654885337745\n",
            "Time elapsed:                             43.16 mins\n",
            "KL between old and new distribution:      0.00999446\n",
            "Entropy:                                  0.04401384\n",
            "Surrogate loss:                           49.792355\n",
            "\n",
            "********** Iteration 124 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 68515\n",
            "Average sum of rewards per episode:       -81.78476821192054\n",
            "Std of rewards per episode:               24.419011289638505\n",
            "Time elapsed:                             43.51 mins\n",
            "KL between old and new distribution:      0.009996262\n",
            "Entropy:                                  0.045277636\n",
            "Surrogate loss:                           44.42649\n",
            "\n",
            "********** Iteration 125 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 69122\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               19.625828925356448\n",
            "Time elapsed:                             43.87 mins\n",
            "KL between old and new distribution:      0.009998676\n",
            "Entropy:                                  0.04090437\n",
            "Surrogate loss:                           42.966576\n",
            "\n",
            "********** Iteration 126 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 69731\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               13.792651880949695\n",
            "Time elapsed:                             44.22 mins\n",
            "KL between old and new distribution:      0.0099992445\n",
            "Entropy:                                  0.03723044\n",
            "Surrogate loss:                           41.598465\n",
            "\n",
            "********** Iteration 127 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 70333\n",
            "Average sum of rewards per episode:       -82.05980066445183\n",
            "Std of rewards per episode:               24.13671770329397\n",
            "Time elapsed:                             44.58 mins\n",
            "KL between old and new distribution:      0.0099773975\n",
            "Entropy:                                  0.043777492\n",
            "Surrogate loss:                           44.44706\n",
            "\n",
            "********** Iteration 128 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 70931\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               22.122786250889735\n",
            "Time elapsed:                             44.93 mins\n",
            "KL between old and new distribution:      0.009985907\n",
            "Entropy:                                  0.04041835\n",
            "Surrogate loss:                           44.1249\n",
            "\n",
            "********** Iteration 129 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 71531\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               18.340922595841974\n",
            "Time elapsed:                             45.29 mins\n",
            "KL between old and new distribution:      0.009978037\n",
            "Entropy:                                  0.0376068\n",
            "Surrogate loss:                           43.118454\n",
            "\n",
            "********** Iteration 130 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 72144\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               19.532398336051546\n",
            "Time elapsed:                             45.64 mins\n",
            "KL between old and new distribution:      0.009975533\n",
            "Entropy:                                  0.035988934\n",
            "Surrogate loss:                           42.557354\n",
            "\n",
            "********** Iteration 131 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 72731\n",
            "Average sum of rewards per episode:       -84.18057921635435\n",
            "Std of rewards per episode:               24.133108257017312\n",
            "Time elapsed:                             45.99 mins\n",
            "KL between old and new distribution:      0.009982657\n",
            "Entropy:                                  0.04118093\n",
            "Surrogate loss:                           45.434536\n",
            "\n",
            "********** Iteration 132 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 73324\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               22.520021529511514\n",
            "Time elapsed:                             46.34 mins\n",
            "KL between old and new distribution:      0.009991359\n",
            "Entropy:                                  0.04301592\n",
            "Surrogate loss:                           44.561665\n",
            "\n",
            "********** Iteration 133 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 73891\n",
            "Average sum of rewards per episode:       -87.18342151675485\n",
            "Std of rewards per episode:               24.979671599752763\n",
            "Time elapsed:                             46.70 mins\n",
            "KL between old and new distribution:      0.009984602\n",
            "Entropy:                                  0.050237637\n",
            "Surrogate loss:                           47.0175\n",
            "\n",
            "********** Iteration 134 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 74436\n",
            "Average sum of rewards per episode:       -90.74495412844037\n",
            "Std of rewards per episode:               27.527185849223898\n",
            "Time elapsed:                             47.05 mins\n",
            "KL between old and new distribution:      0.009999611\n",
            "Entropy:                                  0.055295177\n",
            "Surrogate loss:                           49.35877\n",
            "\n",
            "********** Iteration 135 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 75016\n",
            "Average sum of rewards per episode:       -85.20862068965518\n",
            "Std of rewards per episode:               23.297911586758147\n",
            "Time elapsed:                             47.40 mins\n",
            "KL between old and new distribution:      0.009982912\n",
            "Entropy:                                  0.05427597\n",
            "Surrogate loss:                           45.671246\n",
            "\n",
            "********** Iteration 136 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 75598\n",
            "Average sum of rewards per episode:       -84.91237113402062\n",
            "Std of rewards per episode:               23.501573060161782\n",
            "Time elapsed:                             47.75 mins\n",
            "KL between old and new distribution:      0.009976801\n",
            "Entropy:                                  0.052794453\n",
            "Surrogate loss:                           45.50178\n",
            "\n",
            "********** Iteration 137 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 76191\n",
            "Average sum of rewards per episode:       -83.32040472175379\n",
            "Std of rewards per episode:               26.29682439367952\n",
            "Time elapsed:                             48.11 mins\n",
            "KL between old and new distribution:      0.009996146\n",
            "Entropy:                                  0.05218839\n",
            "Surrogate loss:                           45.58413\n",
            "\n",
            "********** Iteration 138 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 76782\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               23.124592656724502\n",
            "Time elapsed:                             48.46 mins\n",
            "KL between old and new distribution:      0.009975194\n",
            "Entropy:                                  0.051245533\n",
            "Surrogate loss:                           44.83661\n",
            "\n",
            "********** Iteration 139 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 77375\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               21.116666300799185\n",
            "Time elapsed:                             48.81 mins\n",
            "KL between old and new distribution:      0.00998331\n",
            "Entropy:                                  0.049206033\n",
            "Surrogate loss:                           44.181065\n",
            "\n",
            "********** Iteration 140 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 77953\n",
            "Average sum of rewards per episode:       -85.50692041522491\n",
            "Std of rewards per episode:               21.86623664577491\n",
            "Time elapsed:                             49.16 mins\n",
            "KL between old and new distribution:      0.009990327\n",
            "Entropy:                                  0.054233808\n",
            "Surrogate loss:                           45.39766\n",
            "\n",
            "********** Iteration 141 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 78541\n",
            "Average sum of rewards per episode:       -84.0374149659864\n",
            "Std of rewards per episode:               26.497502669862453\n",
            "Time elapsed:                             49.52 mins\n",
            "KL between old and new distribution:      0.009986696\n",
            "Entropy:                                  0.048691425\n",
            "Surrogate loss:                           46.024593\n",
            "\n",
            "********** Iteration 142 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 79137\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               22.376894415848497\n",
            "Time elapsed:                             49.87 mins\n",
            "KL between old and new distribution:      0.009970626\n",
            "Entropy:                                  0.05297541\n",
            "Surrogate loss:                           44.286076\n",
            "\n",
            "********** Iteration 143 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 79737\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               18.598372016568188\n",
            "Time elapsed:                             50.22 mins\n",
            "KL between old and new distribution:      0.009992174\n",
            "Entropy:                                  0.057221483\n",
            "Surrogate loss:                           43.17971\n",
            "\n",
            "********** Iteration 144 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 80306\n",
            "Average sum of rewards per episode:       -86.87697715289983\n",
            "Std of rewards per episode:               35.87332204365289\n",
            "Time elapsed:                             50.57 mins\n",
            "KL between old and new distribution:      0.009999743\n",
            "Entropy:                                  0.051999\n",
            "Surrogate loss:                           50.62617\n",
            "\n",
            "********** Iteration 145 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 80889\n",
            "Average sum of rewards per episode:       -84.76500857632934\n",
            "Std of rewards per episode:               25.081712299906783\n",
            "Time elapsed:                             50.92 mins\n",
            "KL between old and new distribution:      0.009999707\n",
            "Entropy:                                  0.050622553\n",
            "Surrogate loss:                           45.96448\n",
            "\n",
            "********** Iteration 146 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 81471\n",
            "Average sum of rewards per episode:       -84.91237113402062\n",
            "Std of rewards per episode:               22.47039025073519\n",
            "Time elapsed:                             51.27 mins\n",
            "KL between old and new distribution:      0.0099912565\n",
            "Entropy:                                  0.05107681\n",
            "Surrogate loss:                           45.31174\n",
            "\n",
            "********** Iteration 147 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 82052\n",
            "Average sum of rewards per episode:       -85.06024096385542\n",
            "Std of rewards per episode:               26.39697250824694\n",
            "Time elapsed:                             51.63 mins\n",
            "KL between old and new distribution:      0.009979674\n",
            "Entropy:                                  0.05429343\n",
            "Surrogate loss:                           46.49327\n",
            "\n",
            "********** Iteration 148 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 82618\n",
            "Average sum of rewards per episode:       -87.34452296819788\n",
            "Std of rewards per episode:               34.78921429312344\n",
            "Time elapsed:                             51.98 mins\n",
            "KL between old and new distribution:      0.009976523\n",
            "Entropy:                                  0.054220557\n",
            "Surrogate loss:                           50.434437\n",
            "\n",
            "********** Iteration 149 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 83187\n",
            "Average sum of rewards per episode:       -86.87873462214411\n",
            "Std of rewards per episode:               34.06683786816073\n",
            "Time elapsed:                             52.33 mins\n",
            "KL between old and new distribution:      0.009994595\n",
            "Entropy:                                  0.054513536\n",
            "Surrogate loss:                           49.872574\n",
            "\n",
            "********** Iteration 150 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 83779\n",
            "Average sum of rewards per episode:       -83.46283783783784\n",
            "Std of rewards per episode:               28.45275785902861\n",
            "Time elapsed:                             52.69 mins\n",
            "KL between old and new distribution:      0.0099795535\n",
            "Entropy:                                  0.065912455\n",
            "Surrogate loss:                           46.419365\n",
            "\n",
            "********** Iteration 151 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 84355\n",
            "Average sum of rewards per episode:       -85.8125\n",
            "Std of rewards per episode:               39.42736266964015\n",
            "Time elapsed:                             53.04 mins\n",
            "KL between old and new distribution:      0.009986491\n",
            "Entropy:                                  0.060763516\n",
            "Surrogate loss:                           51.74773\n",
            "\n",
            "********** Iteration 152 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 84938\n",
            "Average sum of rewards per episode:       -84.76500857632934\n",
            "Std of rewards per episode:               25.53223523941218\n",
            "Time elapsed:                             53.39 mins\n",
            "KL between old and new distribution:      0.009992709\n",
            "Entropy:                                  0.06557105\n",
            "Surrogate loss:                           46.12184\n",
            "\n",
            "********** Iteration 153 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 85530\n",
            "Average sum of rewards per episode:       -83.46283783783784\n",
            "Std of rewards per episode:               29.481360993019482\n",
            "Time elapsed:                             53.74 mins\n",
            "KL between old and new distribution:      0.009993235\n",
            "Entropy:                                  0.06737058\n",
            "Surrogate loss:                           46.69703\n",
            "\n",
            "********** Iteration 154 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 86115\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               21.8790687396696\n",
            "Time elapsed:                             54.10 mins\n",
            "KL between old and new distribution:      0.009996965\n",
            "Entropy:                                  0.060457535\n",
            "Surrogate loss:                           44.967026\n",
            "\n",
            "********** Iteration 155 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 86701\n",
            "Average sum of rewards per episode:       -84.32764505119454\n",
            "Std of rewards per episode:               28.085653126090243\n",
            "Time elapsed:                             54.45 mins\n",
            "KL between old and new distribution:      0.009999884\n",
            "Entropy:                                  0.059196874\n",
            "Surrogate loss:                           46.62435\n",
            "\n",
            "********** Iteration 156 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 87295\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               23.026643892370114\n",
            "Time elapsed:                             54.81 mins\n",
            "KL between old and new distribution:      0.00999215\n",
            "Entropy:                                  0.064194866\n",
            "Surrogate loss:                           44.62149\n",
            "\n",
            "********** Iteration 157 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 87886\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               22.043540603191374\n",
            "Time elapsed:                             55.16 mins\n",
            "KL between old and new distribution:      0.009977212\n",
            "Entropy:                                  0.064820096\n",
            "Surrogate loss:                           44.52461\n",
            "\n",
            "********** Iteration 158 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 88492\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               19.25636668081423\n",
            "Time elapsed:                             55.51 mins\n",
            "KL between old and new distribution:      0.009981732\n",
            "Entropy:                                  0.054915123\n",
            "Surrogate loss:                           42.91221\n",
            "\n",
            "********** Iteration 159 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 89089\n",
            "Average sum of rewards per episode:       -82.75544388609715\n",
            "Std of rewards per episode:               25.753381811311947\n",
            "Time elapsed:                             55.87 mins\n",
            "KL between old and new distribution:      0.009996273\n",
            "Entropy:                                  0.049742\n",
            "Surrogate loss:                           45.206646\n",
            "\n",
            "********** Iteration 160 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 89689\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               21.332669195391375\n",
            "Time elapsed:                             56.23 mins\n",
            "KL between old and new distribution:      0.009973282\n",
            "Entropy:                                  0.04922097\n",
            "Surrogate loss:                           43.770737\n",
            "\n",
            "********** Iteration 161 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 90300\n",
            "Average sum of rewards per episode:       -80.83469721767594\n",
            "Std of rewards per episode:               17.238972348292123\n",
            "Time elapsed:                             56.58 mins\n",
            "KL between old and new distribution:      0.009989582\n",
            "Entropy:                                  0.051596828\n",
            "Surrogate loss:                           42.124115\n",
            "\n",
            "********** Iteration 162 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 90904\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               16.16290146258746\n",
            "Time elapsed:                             56.93 mins\n",
            "KL between old and new distribution:      0.009980882\n",
            "Entropy:                                  0.04620298\n",
            "Surrogate loss:                           42.36539\n",
            "\n",
            "********** Iteration 163 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 91500\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               24.813070969679544\n",
            "Time elapsed:                             57.29 mins\n",
            "KL between old and new distribution:      0.0099827275\n",
            "Entropy:                                  0.047110517\n",
            "Surrogate loss:                           45.042324\n",
            "\n",
            "********** Iteration 164 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 92101\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               18.599949544004858\n",
            "Time elapsed:                             57.64 mins\n",
            "KL between old and new distribution:      0.009992743\n",
            "Entropy:                                  0.049714517\n",
            "Surrogate loss:                           43.108875\n",
            "\n",
            "********** Iteration 165 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 92692\n",
            "Average sum of rewards per episode:       -83.60406091370558\n",
            "Std of rewards per episode:               23.72435297931899\n",
            "Time elapsed:                             57.99 mins\n",
            "KL between old and new distribution:      0.009981192\n",
            "Entropy:                                  0.04321544\n",
            "Surrogate loss:                           45.04214\n",
            "\n",
            "********** Iteration 166 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 93286\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               22.456333961861006\n",
            "Time elapsed:                             58.35 mins\n",
            "KL between old and new distribution:      0.00999585\n",
            "Entropy:                                  0.043707676\n",
            "Surrogate loss:                           44.507366\n",
            "\n",
            "********** Iteration 167 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 93886\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               20.886345818899645\n",
            "Time elapsed:                             58.70 mins\n",
            "KL between old and new distribution:      0.009995258\n",
            "Entropy:                                  0.048591375\n",
            "Surrogate loss:                           43.686436\n",
            "\n",
            "********** Iteration 168 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 94484\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               22.836256141922192\n",
            "Time elapsed:                             59.06 mins\n",
            "KL between old and new distribution:      0.009977065\n",
            "Entropy:                                  0.044510752\n",
            "Surrogate loss:                           44.324566\n",
            "\n",
            "********** Iteration 169 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 95084\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               21.70904822879161\n",
            "Time elapsed:                             59.41 mins\n",
            "KL between old and new distribution:      0.009976901\n",
            "Entropy:                                  0.0453229\n",
            "Surrogate loss:                           43.911\n",
            "\n",
            "********** Iteration 170 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 95686\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               21.049576234727223\n",
            "Time elapsed:                             59.76 mins\n",
            "KL between old and new distribution:      0.009985238\n",
            "Entropy:                                  0.046372406\n",
            "Surrogate loss:                           43.55008\n",
            "\n",
            "********** Iteration 171 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 96294\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               17.813840873256996\n",
            "Time elapsed:                             60.12 mins\n",
            "KL between old and new distribution:      0.009964787\n",
            "Entropy:                                  0.04737554\n",
            "Surrogate loss:                           42.42646\n",
            "\n",
            "********** Iteration 172 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 96901\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               17.432482544463987\n",
            "Time elapsed:                             60.47 mins\n",
            "KL between old and new distribution:      0.009981494\n",
            "Entropy:                                  0.04666826\n",
            "Surrogate loss:                           42.462036\n",
            "\n",
            "********** Iteration 173 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 97491\n",
            "Average sum of rewards per episode:       -83.75084745762712\n",
            "Std of rewards per episode:               33.96260093093107\n",
            "Time elapsed:                             60.83 mins\n",
            "KL between old and new distribution:      0.009998411\n",
            "Entropy:                                  0.03875275\n",
            "Surrogate loss:                           48.553825\n",
            "\n",
            "********** Iteration 174 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 98104\n",
            "Average sum of rewards per episode:       -80.56933115823817\n",
            "Std of rewards per episode:               23.016566252699068\n",
            "Time elapsed:                             61.18 mins\n",
            "KL between old and new distribution:      0.0058216187\n",
            "Entropy:                                  0.040663898\n",
            "Surrogate loss:                           43.509476\n",
            "\n",
            "********** Iteration 175 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 98701\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               23.112310598600878\n",
            "Time elapsed:                             61.54 mins\n",
            "KL between old and new distribution:      0.009978259\n",
            "Entropy:                                  0.040165074\n",
            "Surrogate loss:                           44.45513\n",
            "\n",
            "********** Iteration 176 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 99311\n",
            "Average sum of rewards per episode:       -80.96885245901639\n",
            "Std of rewards per episode:               18.278465704736142\n",
            "Time elapsed:                             61.90 mins\n",
            "KL between old and new distribution:      0.009971306\n",
            "Entropy:                                  0.03971576\n",
            "Surrogate loss:                           42.41815\n",
            "\n",
            "********** Iteration 177 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 99918\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               16.09158859809445\n",
            "Time elapsed:                             62.25 mins\n",
            "KL between old and new distribution:      0.009975959\n",
            "Entropy:                                  0.042577166\n",
            "Surrogate loss:                           42.138355\n",
            "\n",
            "********** Iteration 178 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 100511\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               20.697074856904937\n",
            "Time elapsed:                             62.61 mins\n",
            "KL between old and new distribution:      0.009982752\n",
            "Entropy:                                  0.040989473\n",
            "Surrogate loss:                           44.024456\n",
            "\n",
            "********** Iteration 179 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 101108\n",
            "Average sum of rewards per episode:       -82.7571189279732\n",
            "Std of rewards per episode:               31.165785212534427\n",
            "Time elapsed:                             62.96 mins\n",
            "KL between old and new distribution:      0.00999446\n",
            "Entropy:                                  0.04168956\n",
            "Surrogate loss:                           47.08203\n",
            "\n",
            "********** Iteration 180 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 101698\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               23.131069837805274\n",
            "Time elapsed:                             63.32 mins\n",
            "KL between old and new distribution:      0.005780086\n",
            "Entropy:                                  0.042736147\n",
            "Surrogate loss:                           45.016865\n",
            "\n",
            "********** Iteration 181 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 102297\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               18.600417757657016\n",
            "Time elapsed:                             63.67 mins\n",
            "KL between old and new distribution:      0.009996564\n",
            "Entropy:                                  0.044521734\n",
            "Surrogate loss:                           43.19699\n",
            "\n",
            "********** Iteration 182 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 102898\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               22.13289282951781\n",
            "Time elapsed:                             64.03 mins\n",
            "KL between old and new distribution:      0.009971382\n",
            "Entropy:                                  0.044066846\n",
            "Surrogate loss:                           43.92948\n",
            "\n",
            "********** Iteration 183 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 103499\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               19.104007818257898\n",
            "Time elapsed:                             64.38 mins\n",
            "KL between old and new distribution:      0.009981335\n",
            "Entropy:                                  0.0448401\n",
            "Surrogate loss:                           43.2053\n",
            "\n",
            "********** Iteration 184 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 104093\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               21.540598244177662\n",
            "Time elapsed:                             64.74 mins\n",
            "KL between old and new distribution:      0.0099795\n",
            "Entropy:                                  0.046327773\n",
            "Surrogate loss:                           44.291584\n",
            "\n",
            "********** Iteration 185 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 104679\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               20.941766558159095\n",
            "Time elapsed:                             65.10 mins\n",
            "KL between old and new distribution:      0.009981593\n",
            "Entropy:                                  0.047743857\n",
            "Surrogate loss:                           44.64052\n",
            "\n",
            "********** Iteration 186 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 105249\n",
            "Average sum of rewards per episode:       -86.72105263157894\n",
            "Std of rewards per episode:               24.686406777692884\n",
            "Time elapsed:                             65.45 mins\n",
            "KL between old and new distribution:      0.0099758115\n",
            "Entropy:                                  0.04526555\n",
            "Surrogate loss:                           46.742447\n",
            "\n",
            "********** Iteration 187 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 105827\n",
            "Average sum of rewards per episode:       -85.50692041522491\n",
            "Std of rewards per episode:               26.113489080730766\n",
            "Time elapsed:                             65.80 mins\n",
            "KL between old and new distribution:      0.00997733\n",
            "Entropy:                                  0.043013256\n",
            "Surrogate loss:                           46.6103\n",
            "\n",
            "********** Iteration 188 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 106411\n",
            "Average sum of rewards per episode:       -84.62157534246575\n",
            "Std of rewards per episode:               32.55957048849091\n",
            "Time elapsed:                             66.16 mins\n",
            "KL between old and new distribution:      0.0099903215\n",
            "Entropy:                                  0.039182145\n",
            "Surrogate loss:                           48.442665\n",
            "\n",
            "********** Iteration 189 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 107004\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               20.219068447389425\n",
            "Time elapsed:                             66.51 mins\n",
            "KL between old and new distribution:      0.009975819\n",
            "Entropy:                                  0.03662119\n",
            "Surrogate loss:                           44.017956\n",
            "\n",
            "********** Iteration 190 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 107589\n",
            "Average sum of rewards per episode:       -84.47521367521368\n",
            "Std of rewards per episode:               30.987394475937055\n",
            "Time elapsed:                             66.87 mins\n",
            "KL between old and new distribution:      0.009993411\n",
            "Entropy:                                  0.032903668\n",
            "Surrogate loss:                           47.7352\n",
            "\n",
            "********** Iteration 191 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 108183\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               19.729843714191706\n",
            "Time elapsed:                             67.23 mins\n",
            "KL between old and new distribution:      0.009980461\n",
            "Entropy:                                  0.02953818\n",
            "Surrogate loss:                           43.768925\n",
            "\n",
            "********** Iteration 192 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 108776\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               21.072218318599678\n",
            "Time elapsed:                             67.58 mins\n",
            "KL between old and new distribution:      0.009987384\n",
            "Entropy:                                  0.028231202\n",
            "Surrogate loss:                           44.23021\n",
            "\n",
            "********** Iteration 193 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 109371\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               24.26811924043799\n",
            "Time elapsed:                             67.94 mins\n",
            "KL between old and new distribution:      0.009987419\n",
            "Entropy:                                  0.02654144\n",
            "Surrogate loss:                           44.953854\n",
            "\n",
            "********** Iteration 194 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 109964\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               24.774285008510674\n",
            "Time elapsed:                             68.29 mins\n",
            "KL between old and new distribution:      0.00999803\n",
            "Entropy:                                  0.026879715\n",
            "Surrogate loss:                           45.212986\n",
            "\n",
            "********** Iteration 195 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 110573\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               16.731457778884725\n",
            "Time elapsed:                             68.65 mins\n",
            "KL between old and new distribution:      0.009997761\n",
            "Entropy:                                  0.028469866\n",
            "Surrogate loss:                           42.214905\n",
            "\n",
            "********** Iteration 196 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 111174\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               24.358690650926754\n",
            "Time elapsed:                             69.01 mins\n",
            "KL between old and new distribution:      0.009995458\n",
            "Entropy:                                  0.027815476\n",
            "Surrogate loss:                           44.602444\n",
            "\n",
            "********** Iteration 197 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 111772\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               22.04653665603664\n",
            "Time elapsed:                             69.36 mins\n",
            "KL between old and new distribution:      0.009970055\n",
            "Entropy:                                  0.026560979\n",
            "Surrogate loss:                           44.121895\n",
            "\n",
            "********** Iteration 198 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 112357\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               25.311386735772437\n",
            "Time elapsed:                             69.72 mins\n",
            "KL between old and new distribution:      0.0088725025\n",
            "Entropy:                                  0.027134392\n",
            "Surrogate loss:                           45.936443\n",
            "\n",
            "********** Iteration 199 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 112949\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               20.452280749828258\n",
            "Time elapsed:                             70.07 mins\n",
            "KL between old and new distribution:      0.009970897\n",
            "Entropy:                                  0.02691438\n",
            "Surrogate loss:                           44.10955\n",
            "\n",
            "********** Iteration 200 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 113542\n",
            "Average sum of rewards per episode:       -83.32040472175379\n",
            "Std of rewards per episode:               27.83979472794067\n",
            "Time elapsed:                             70.43 mins\n",
            "KL between old and new distribution:      0.009990105\n",
            "Entropy:                                  0.022791909\n",
            "Surrogate loss:                           46.21796\n",
            "\n",
            "********** Iteration 201 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 114144\n",
            "Average sum of rewards per episode:       -82.05980066445183\n",
            "Std of rewards per episode:               26.857871492168428\n",
            "Time elapsed:                             70.78 mins\n",
            "KL between old and new distribution:      0.009991388\n",
            "Entropy:                                  0.023371523\n",
            "Surrogate loss:                           45.28376\n",
            "\n",
            "********** Iteration 202 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 114735\n",
            "Average sum of rewards per episode:       -83.60575296108291\n",
            "Std of rewards per episode:               27.484409992258502\n",
            "Time elapsed:                             71.14 mins\n",
            "KL between old and new distribution:      0.0099707665\n",
            "Entropy:                                  0.023509711\n",
            "Surrogate loss:                           46.15693\n",
            "\n",
            "********** Iteration 203 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 115323\n",
            "Average sum of rewards per episode:       -84.0374149659864\n",
            "Std of rewards per episode:               28.813592103662444\n",
            "Time elapsed:                             71.50 mins\n",
            "KL between old and new distribution:      0.009982869\n",
            "Entropy:                                  0.022187255\n",
            "Surrogate loss:                           46.80277\n",
            "\n",
            "********** Iteration 204 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 115918\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               25.887967632841097\n",
            "Time elapsed:                             71.86 mins\n",
            "KL between old and new distribution:      0.0050630965\n",
            "Entropy:                                  0.021258706\n",
            "Surrogate loss:                           45.48242\n",
            "\n",
            "********** Iteration 205 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 116502\n",
            "Average sum of rewards per episode:       -84.6181506849315\n",
            "Std of rewards per episode:               23.78794184880129\n",
            "Time elapsed:                             72.22 mins\n",
            "KL between old and new distribution:      0.009986552\n",
            "Entropy:                                  0.021996392\n",
            "Surrogate loss:                           45.562035\n",
            "\n",
            "********** Iteration 206 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 117098\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               22.981767671542805\n",
            "Time elapsed:                             72.58 mins\n",
            "KL between old and new distribution:      0.009974286\n",
            "Entropy:                                  0.028015556\n",
            "Surrogate loss:                           44.52154\n",
            "\n",
            "********** Iteration 207 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 117675\n",
            "Average sum of rewards per episode:       -85.66031195840554\n",
            "Std of rewards per episode:               32.49645817639415\n",
            "Time elapsed:                             72.93 mins\n",
            "KL between old and new distribution:      0.0099902665\n",
            "Entropy:                                  0.026690893\n",
            "Surrogate loss:                           48.80661\n",
            "\n",
            "********** Iteration 208 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 118252\n",
            "Average sum of rewards per episode:       -85.65684575389947\n",
            "Std of rewards per episode:               24.327205369159483\n",
            "Time elapsed:                             73.29 mins\n",
            "KL between old and new distribution:      0.009993167\n",
            "Entropy:                                  0.025491757\n",
            "Surrogate loss:                           46.13112\n",
            "\n",
            "********** Iteration 209 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 118819\n",
            "Average sum of rewards per episode:       -87.18694885361552\n",
            "Std of rewards per episode:               34.10809105656541\n",
            "Time elapsed:                             73.65 mins\n",
            "KL between old and new distribution:      0.009969539\n",
            "Entropy:                                  0.022622114\n",
            "Surrogate loss:                           50.10328\n",
            "\n",
            "********** Iteration 210 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 119398\n",
            "Average sum of rewards per episode:       -85.36096718480138\n",
            "Std of rewards per episode:               35.3483908474869\n",
            "Time elapsed:                             74.01 mins\n",
            "KL between old and new distribution:      0.009969565\n",
            "Entropy:                                  0.0219972\n",
            "Surrogate loss:                           49.83896\n",
            "\n",
            "********** Iteration 211 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 119995\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               24.873374597202623\n",
            "Time elapsed:                             74.37 mins\n",
            "KL between old and new distribution:      0.009987045\n",
            "Entropy:                                  0.020956468\n",
            "Surrogate loss:                           44.95091\n",
            "\n",
            "********** Iteration 212 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 120590\n",
            "Average sum of rewards per episode:       -83.03865546218488\n",
            "Std of rewards per episode:               30.93175222439249\n",
            "Time elapsed:                             74.73 mins\n",
            "KL between old and new distribution:      0.009989979\n",
            "Entropy:                                  0.01925312\n",
            "Surrogate loss:                           47.13621\n",
            "\n",
            "********** Iteration 213 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 121189\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               20.638851352890452\n",
            "Time elapsed:                             75.09 mins\n",
            "KL between old and new distribution:      0.0076071173\n",
            "Entropy:                                  0.021184433\n",
            "Surrogate loss:                           43.75774\n",
            "\n",
            "********** Iteration 214 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 121791\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               19.11344715951051\n",
            "Time elapsed:                             75.45 mins\n",
            "KL between old and new distribution:      0.009992793\n",
            "Entropy:                                  0.021799633\n",
            "Surrogate loss:                           43.140957\n",
            "\n",
            "********** Iteration 215 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 122393\n",
            "Average sum of rewards per episode:       -82.06146179401993\n",
            "Std of rewards per episode:               29.871394496388\n",
            "Time elapsed:                             75.81 mins\n",
            "KL between old and new distribution:      0.0099993935\n",
            "Entropy:                                  0.021223646\n",
            "Surrogate loss:                           46.32221\n",
            "\n",
            "********** Iteration 216 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 122992\n",
            "Average sum of rewards per episode:       -82.47579298831386\n",
            "Std of rewards per episode:               28.542836009695055\n",
            "Time elapsed:                             76.17 mins\n",
            "KL between old and new distribution:      0.009976991\n",
            "Entropy:                                  0.021258242\n",
            "Surrogate loss:                           46.044643\n",
            "\n",
            "********** Iteration 217 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 123598\n",
            "Average sum of rewards per episode:       -81.51155115511551\n",
            "Std of rewards per episode:               25.696676312346476\n",
            "Time elapsed:                             76.53 mins\n",
            "KL between old and new distribution:      0.009980285\n",
            "Entropy:                                  0.019955749\n",
            "Surrogate loss:                           44.68168\n",
            "\n",
            "********** Iteration 218 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 124199\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               22.851864411162357\n",
            "Time elapsed:                             76.89 mins\n",
            "KL between old and new distribution:      0.0099988915\n",
            "Entropy:                                  0.019286523\n",
            "Surrogate loss:                           44.143734\n",
            "\n",
            "********** Iteration 219 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 124794\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               19.669122618392525\n",
            "Time elapsed:                             77.24 mins\n",
            "KL between old and new distribution:      0.009970385\n",
            "Entropy:                                  0.018392926\n",
            "Surrogate loss:                           43.734585\n",
            "\n",
            "********** Iteration 220 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 125387\n",
            "Average sum of rewards per episode:       -83.3220910623946\n",
            "Std of rewards per episode:               30.159986016315642\n",
            "Time elapsed:                             77.61 mins\n",
            "KL between old and new distribution:      0.00998284\n",
            "Entropy:                                  0.020467376\n",
            "Surrogate loss:                           47.012924\n",
            "\n",
            "********** Iteration 221 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 125982\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               20.014207509277483\n",
            "Time elapsed:                             77.97 mins\n",
            "KL between old and new distribution:      0.009973055\n",
            "Entropy:                                  0.019466298\n",
            "Surrogate loss:                           43.80152\n",
            "\n",
            "********** Iteration 222 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 126580\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               20.925803291843074\n",
            "Time elapsed:                             78.32 mins\n",
            "KL between old and new distribution:      0.009989777\n",
            "Entropy:                                  0.019307973\n",
            "Surrogate loss:                           43.831306\n",
            "\n",
            "********** Iteration 223 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 127174\n",
            "Average sum of rewards per episode:       -83.17845117845118\n",
            "Std of rewards per episode:               25.986434047470016\n",
            "Time elapsed:                             78.68 mins\n",
            "KL between old and new distribution:      0.009994196\n",
            "Entropy:                                  0.021737168\n",
            "Surrogate loss:                           45.55796\n",
            "\n",
            "********** Iteration 224 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 127773\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               19.525136784895473\n",
            "Time elapsed:                             79.05 mins\n",
            "KL between old and new distribution:      0.00998802\n",
            "Entropy:                                  0.024946483\n",
            "Surrogate loss:                           43.41277\n",
            "\n",
            "********** Iteration 225 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 128370\n",
            "Average sum of rewards per episode:       -82.75544388609715\n",
            "Std of rewards per episode:               27.879265147022323\n",
            "Time elapsed:                             79.41 mins\n",
            "KL between old and new distribution:      0.009985516\n",
            "Entropy:                                  0.023314996\n",
            "Surrogate loss:                           45.90471\n",
            "\n",
            "********** Iteration 226 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 128965\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               28.39709970261704\n",
            "Time elapsed:                             79.77 mins\n",
            "KL between old and new distribution:      0.009992339\n",
            "Entropy:                                  0.023141282\n",
            "Surrogate loss:                           46.154156\n",
            "\n",
            "********** Iteration 227 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 129575\n",
            "Average sum of rewards per episode:       -80.97049180327869\n",
            "Std of rewards per episode:               21.359432548045913\n",
            "Time elapsed:                             80.13 mins\n",
            "KL between old and new distribution:      0.009997166\n",
            "Entropy:                                  0.021353476\n",
            "Surrogate loss:                           43.18108\n",
            "\n",
            "********** Iteration 228 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 130164\n",
            "Average sum of rewards per episode:       -83.893039049236\n",
            "Std of rewards per episode:               31.54817539731899\n",
            "Time elapsed:                             80.49 mins\n",
            "KL between old and new distribution:      0.009995765\n",
            "Entropy:                                  0.018663615\n",
            "Surrogate loss:                           47.697865\n",
            "\n",
            "********** Iteration 229 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 130773\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               15.705127793574729\n",
            "Time elapsed:                             80.85 mins\n",
            "KL between old and new distribution:      0.009991482\n",
            "Entropy:                                  0.018122053\n",
            "Surrogate loss:                           41.99733\n",
            "\n",
            "********** Iteration 230 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 131367\n",
            "Average sum of rewards per episode:       -83.17845117845118\n",
            "Std of rewards per episode:               28.699918586889428\n",
            "Time elapsed:                             81.21 mins\n",
            "KL between old and new distribution:      0.009987501\n",
            "Entropy:                                  0.018704882\n",
            "Surrogate loss:                           46.40409\n",
            "\n",
            "********** Iteration 231 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 131961\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               23.934268832970886\n",
            "Time elapsed:                             81.57 mins\n",
            "KL between old and new distribution:      0.009397777\n",
            "Entropy:                                  0.019584464\n",
            "Surrogate loss:                           44.94197\n",
            "\n",
            "********** Iteration 232 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 132561\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               20.330997065236783\n",
            "Time elapsed:                             81.93 mins\n",
            "KL between old and new distribution:      0.009992993\n",
            "Entropy:                                  0.019441267\n",
            "Surrogate loss:                           43.55193\n",
            "\n",
            "********** Iteration 233 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 133159\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               22.965430162297093\n",
            "Time elapsed:                             82.29 mins\n",
            "KL between old and new distribution:      0.009998354\n",
            "Entropy:                                  0.017070504\n",
            "Surrogate loss:                           44.39803\n",
            "\n",
            "********** Iteration 234 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 133770\n",
            "Average sum of rewards per episode:       -80.83469721767594\n",
            "Std of rewards per episode:               18.687817978135826\n",
            "Time elapsed:                             82.65 mins\n",
            "KL between old and new distribution:      0.009976714\n",
            "Entropy:                                  0.018995386\n",
            "Surrogate loss:                           42.422176\n",
            "\n",
            "********** Iteration 235 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 134373\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               21.67015582714927\n",
            "Time elapsed:                             83.02 mins\n",
            "KL between old and new distribution:      0.009993034\n",
            "Entropy:                                  0.021379497\n",
            "Surrogate loss:                           43.631084\n",
            "\n",
            "********** Iteration 236 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 134972\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               20.606875561134533\n",
            "Time elapsed:                             83.38 mins\n",
            "KL between old and new distribution:      0.009987152\n",
            "Entropy:                                  0.015672335\n",
            "Surrogate loss:                           43.735355\n",
            "\n",
            "********** Iteration 237 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 135577\n",
            "Average sum of rewards per episode:       -81.64628099173554\n",
            "Std of rewards per episode:               18.98735134141584\n",
            "Time elapsed:                             83.74 mins\n",
            "KL between old and new distribution:      0.009974841\n",
            "Entropy:                                  0.01673212\n",
            "Surrogate loss:                           42.89082\n",
            "\n",
            "********** Iteration 238 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 136187\n",
            "Average sum of rewards per episode:       -80.96885245901639\n",
            "Std of rewards per episode:               17.637813709574143\n",
            "Time elapsed:                             84.10 mins\n",
            "KL between old and new distribution:      0.009992699\n",
            "Entropy:                                  0.019420777\n",
            "Surrogate loss:                           42.308205\n",
            "\n",
            "********** Iteration 239 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 136790\n",
            "Average sum of rewards per episode:       -81.92205638474296\n",
            "Std of rewards per episode:               24.934918161051044\n",
            "Time elapsed:                             84.46 mins\n",
            "KL between old and new distribution:      0.009988872\n",
            "Entropy:                                  0.017736059\n",
            "Surrogate loss:                           44.62625\n",
            "\n",
            "********** Iteration 240 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 137396\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               19.031736591282623\n",
            "Time elapsed:                             84.82 mins\n",
            "KL between old and new distribution:      0.009970975\n",
            "Entropy:                                  0.02155156\n",
            "Surrogate loss:                           42.875656\n",
            "\n",
            "********** Iteration 241 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 137993\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               20.93040249917301\n",
            "Time elapsed:                             85.18 mins\n",
            "KL between old and new distribution:      0.0099907145\n",
            "Entropy:                                  0.01765218\n",
            "Surrogate loss:                           43.935226\n",
            "\n",
            "********** Iteration 242 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 138600\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               18.97801158644045\n",
            "Time elapsed:                             85.54 mins\n",
            "KL between old and new distribution:      0.009975033\n",
            "Entropy:                                  0.01623509\n",
            "Surrogate loss:                           42.78201\n",
            "\n",
            "********** Iteration 243 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 139206\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               17.710517870026287\n",
            "Time elapsed:                             85.91 mins\n",
            "KL between old and new distribution:      0.009984583\n",
            "Entropy:                                  0.018576395\n",
            "Surrogate loss:                           42.56895\n",
            "\n",
            "********** Iteration 244 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 139817\n",
            "Average sum of rewards per episode:       -80.83960720130933\n",
            "Std of rewards per episode:               32.64053792523425\n",
            "Time elapsed:                             86.27 mins\n",
            "KL between old and new distribution:      0.009997588\n",
            "Entropy:                                  0.019273369\n",
            "Surrogate loss:                           46.84785\n",
            "\n",
            "********** Iteration 245 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 140428\n",
            "Average sum of rewards per episode:       -80.83633387888707\n",
            "Std of rewards per episode:               23.452903441775497\n",
            "Time elapsed:                             86.63 mins\n",
            "KL between old and new distribution:      0.009992207\n",
            "Entropy:                                  0.01868331\n",
            "Surrogate loss:                           43.66033\n",
            "\n",
            "********** Iteration 246 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 141018\n",
            "Average sum of rewards per episode:       -83.74915254237288\n",
            "Std of rewards per episode:               27.998210432408158\n",
            "Time elapsed:                             86.99 mins\n",
            "KL between old and new distribution:      0.0014049355\n",
            "Entropy:                                  0.016127367\n",
            "Surrogate loss:                           46.48046\n",
            "\n",
            "********** Iteration 247 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 141618\n",
            "Average sum of rewards per episode:       -82.33666666666667\n",
            "Std of rewards per episode:               28.79716401931891\n",
            "Time elapsed:                             87.35 mins\n",
            "KL between old and new distribution:      0.009974122\n",
            "Entropy:                                  0.015217317\n",
            "Surrogate loss:                           46.02934\n",
            "\n",
            "********** Iteration 248 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 142217\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               19.737735733307744\n",
            "Time elapsed:                             87.71 mins\n",
            "KL between old and new distribution:      0.009996003\n",
            "Entropy:                                  0.01643848\n",
            "Surrogate loss:                           43.47301\n",
            "\n",
            "********** Iteration 249 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 142811\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               21.960802216597898\n",
            "Time elapsed:                             88.07 mins\n",
            "KL between old and new distribution:      0.009970551\n",
            "Entropy:                                  0.018994693\n",
            "Surrogate loss:                           44.365746\n",
            "\n",
            "********** Iteration 250 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 143388\n",
            "Average sum of rewards per episode:       -85.65857885615252\n",
            "Std of rewards per episode:               25.484209949153154\n",
            "Time elapsed:                             88.43 mins\n",
            "KL between old and new distribution:      0.009971855\n",
            "Entropy:                                  0.01889244\n",
            "Surrogate loss:                           46.520126\n",
            "\n",
            "********** Iteration 251 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 143981\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               20.03802297210581\n",
            "Time elapsed:                             88.79 mins\n",
            "KL between old and new distribution:      0.00997103\n",
            "Entropy:                                  0.018055292\n",
            "Surrogate loss:                           43.910854\n",
            "\n",
            "********** Iteration 252 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 144555\n",
            "Average sum of rewards per episode:       -86.11324041811847\n",
            "Std of rewards per episode:               31.028637985157772\n",
            "Time elapsed:                             89.16 mins\n",
            "KL between old and new distribution:      0.009989941\n",
            "Entropy:                                  0.018328302\n",
            "Surrogate loss:                           48.50286\n",
            "\n",
            "********** Iteration 253 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 145090\n",
            "Average sum of rewards per episode:       -92.46542056074766\n",
            "Std of rewards per episode:               41.80424139551996\n",
            "Time elapsed:                             89.52 mins\n",
            "KL between old and new distribution:      0.009968012\n",
            "Entropy:                                  0.02444307\n",
            "Surrogate loss:                           55.260796\n",
            "\n",
            "********** Iteration 254 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 145648\n",
            "Average sum of rewards per episode:       -88.61111111111111\n",
            "Std of rewards per episode:               37.89909757465628\n",
            "Time elapsed:                             89.88 mins\n",
            "KL between old and new distribution:      0.0099831205\n",
            "Entropy:                                  0.016753945\n",
            "Surrogate loss:                           52.20347\n",
            "\n",
            "********** Iteration 255 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 146211\n",
            "Average sum of rewards per episode:       -87.81172291296625\n",
            "Std of rewards per episode:               27.309359960214085\n",
            "Time elapsed:                             90.24 mins\n",
            "KL between old and new distribution:      0.009993176\n",
            "Entropy:                                  0.02188534\n",
            "Surrogate loss:                           47.96714\n",
            "\n",
            "********** Iteration 256 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 146798\n",
            "Average sum of rewards per episode:       -84.18057921635435\n",
            "Std of rewards per episode:               20.915374984392756\n",
            "Time elapsed:                             90.60 mins\n",
            "KL between old and new distribution:      0.007273241\n",
            "Entropy:                                  0.01730912\n",
            "Surrogate loss:                           44.573826\n",
            "\n",
            "********** Iteration 257 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 147396\n",
            "Average sum of rewards per episode:       -82.61538461538461\n",
            "Std of rewards per episode:               22.920231692517703\n",
            "Time elapsed:                             90.96 mins\n",
            "KL between old and new distribution:      0.009977189\n",
            "Entropy:                                  0.015764873\n",
            "Surrogate loss:                           44.36582\n",
            "\n",
            "********** Iteration 258 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 147984\n",
            "Average sum of rewards per episode:       -84.03571428571429\n",
            "Std of rewards per episode:               24.431921588712722\n",
            "Time elapsed:                             91.32 mins\n",
            "KL between old and new distribution:      0.009992892\n",
            "Entropy:                                  0.016190158\n",
            "Surrogate loss:                           45.47802\n",
            "\n",
            "********** Iteration 259 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 148556\n",
            "Average sum of rewards per episode:       -86.41608391608392\n",
            "Std of rewards per episode:               28.260865601117505\n",
            "Time elapsed:                             91.68 mins\n",
            "KL between old and new distribution:      0.009968895\n",
            "Entropy:                                  0.018903341\n",
            "Surrogate loss:                           47.68012\n",
            "\n",
            "********** Iteration 260 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 149142\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               22.56030015071661\n",
            "Time elapsed:                             92.04 mins\n",
            "KL between old and new distribution:      0.009252664\n",
            "Entropy:                                  0.017562453\n",
            "Surrogate loss:                           45.08079\n",
            "\n",
            "********** Iteration 261 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 149735\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               21.137658593996967\n",
            "Time elapsed:                             92.40 mins\n",
            "KL between old and new distribution:      0.009970869\n",
            "Entropy:                                  0.016435081\n",
            "Surrogate loss:                           44.22609\n",
            "\n",
            "********** Iteration 262 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 150330\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               29.44389870041053\n",
            "Time elapsed:                             92.76 mins\n",
            "KL between old and new distribution:      0.0061322316\n",
            "Entropy:                                  0.015777174\n",
            "Surrogate loss:                           46.61196\n",
            "\n",
            "********** Iteration 263 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 150916\n",
            "Average sum of rewards per episode:       -84.3259385665529\n",
            "Std of rewards per episode:               24.072868110549233\n",
            "Time elapsed:                             93.12 mins\n",
            "KL between old and new distribution:      0.009979983\n",
            "Entropy:                                  0.014287905\n",
            "Surrogate loss:                           45.472046\n",
            "\n",
            "********** Iteration 264 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 151511\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               20.56611632953294\n",
            "Time elapsed:                             93.48 mins\n",
            "KL between old and new distribution:      0.00997899\n",
            "Entropy:                                  0.014344856\n",
            "Surrogate loss:                           43.94418\n",
            "\n",
            "********** Iteration 265 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 152089\n",
            "Average sum of rewards per episode:       -85.50692041522491\n",
            "Std of rewards per episode:               25.143686472132348\n",
            "Time elapsed:                             93.84 mins\n",
            "KL between old and new distribution:      0.009997568\n",
            "Entropy:                                  0.017759182\n",
            "Surrogate loss:                           46.237934\n",
            "\n",
            "********** Iteration 266 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 152682\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               21.589562551697103\n",
            "Time elapsed:                             94.20 mins\n",
            "KL between old and new distribution:      0.009979049\n",
            "Entropy:                                  0.018386666\n",
            "Surrogate loss:                           44.31458\n",
            "\n",
            "********** Iteration 267 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 153272\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               24.21021535291756\n",
            "Time elapsed:                             94.56 mins\n",
            "KL between old and new distribution:      0.009977802\n",
            "Entropy:                                  0.016594421\n",
            "Surrogate loss:                           45.274036\n",
            "\n",
            "********** Iteration 268 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 153865\n",
            "Average sum of rewards per episode:       -83.32040472175379\n",
            "Std of rewards per episode:               28.21625484136693\n",
            "Time elapsed:                             94.92 mins\n",
            "KL between old and new distribution:      0.009969237\n",
            "Entropy:                                  0.01635598\n",
            "Surrogate loss:                           46.253914\n",
            "\n",
            "********** Iteration 269 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 154464\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               21.072153210488658\n",
            "Time elapsed:                             95.28 mins\n",
            "KL between old and new distribution:      0.008023699\n",
            "Entropy:                                  0.016120486\n",
            "Surrogate loss:                           43.874374\n",
            "\n",
            "********** Iteration 270 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 155045\n",
            "Average sum of rewards per episode:       -85.06024096385542\n",
            "Std of rewards per episode:               29.12176619016916\n",
            "Time elapsed:                             95.64 mins\n",
            "KL between old and new distribution:      0.009977586\n",
            "Entropy:                                  0.01844817\n",
            "Surrogate loss:                           47.347103\n",
            "\n",
            "********** Iteration 271 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 155642\n",
            "Average sum of rewards per episode:       -82.75544388609715\n",
            "Std of rewards per episode:               25.39709076071161\n",
            "Time elapsed:                             96.00 mins\n",
            "KL between old and new distribution:      0.009994975\n",
            "Entropy:                                  0.016870786\n",
            "Surrogate loss:                           45.15717\n",
            "\n",
            "********** Iteration 272 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 156233\n",
            "Average sum of rewards per episode:       -83.60575296108291\n",
            "Std of rewards per episode:               27.377264655800193\n",
            "Time elapsed:                             96.36 mins\n",
            "KL between old and new distribution:      0.009971839\n",
            "Entropy:                                  0.01771366\n",
            "Surrogate loss:                           46.14\n",
            "\n",
            "********** Iteration 273 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 156815\n",
            "Average sum of rewards per episode:       -84.91237113402062\n",
            "Std of rewards per episode:               24.036646239002657\n",
            "Time elapsed:                             96.72 mins\n",
            "KL between old and new distribution:      0.009979945\n",
            "Entropy:                                  0.017567027\n",
            "Surrogate loss:                           45.761005\n",
            "\n",
            "********** Iteration 274 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 157389\n",
            "Average sum of rewards per episode:       -86.11149825783973\n",
            "Std of rewards per episode:               28.595486599335644\n",
            "Time elapsed:                             97.09 mins\n",
            "KL between old and new distribution:      0.009990677\n",
            "Entropy:                                  0.01627248\n",
            "Surrogate loss:                           47.647915\n",
            "\n",
            "********** Iteration 275 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 157981\n",
            "Average sum of rewards per episode:       -83.46283783783784\n",
            "Std of rewards per episode:               27.55317900039408\n",
            "Time elapsed:                             97.44 mins\n",
            "KL between old and new distribution:      0.009987985\n",
            "Entropy:                                  0.018335043\n",
            "Surrogate loss:                           46.168743\n",
            "\n",
            "********** Iteration 276 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 158570\n",
            "Average sum of rewards per episode:       -83.89134125636673\n",
            "Std of rewards per episode:               23.897526203405604\n",
            "Time elapsed:                             97.80 mins\n",
            "KL between old and new distribution:      0.009969241\n",
            "Entropy:                                  0.01802852\n",
            "Surrogate loss:                           45.23809\n",
            "\n",
            "********** Iteration 277 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 159145\n",
            "Average sum of rewards per episode:       -85.95826086956522\n",
            "Std of rewards per episode:               26.692092894008553\n",
            "Time elapsed:                             98.16 mins\n",
            "KL between old and new distribution:      0.009977081\n",
            "Entropy:                                  0.016672729\n",
            "Surrogate loss:                           47.000584\n",
            "\n",
            "********** Iteration 278 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 159737\n",
            "Average sum of rewards per episode:       -83.46283783783784\n",
            "Std of rewards per episode:               24.009963529823054\n",
            "Time elapsed:                             98.52 mins\n",
            "KL between old and new distribution:      0.009992165\n",
            "Entropy:                                  0.01611855\n",
            "Surrogate loss:                           45.06293\n",
            "\n",
            "********** Iteration 279 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 160331\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               18.416452505447943\n",
            "Time elapsed:                             98.88 mins\n",
            "KL between old and new distribution:      0.009979707\n",
            "Entropy:                                  0.015654687\n",
            "Surrogate loss:                           43.566593\n",
            "\n",
            "********** Iteration 280 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 160927\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               19.076512342698255\n",
            "Time elapsed:                             99.25 mins\n",
            "KL between old and new distribution:      0.009985263\n",
            "Entropy:                                  0.015329724\n",
            "Surrogate loss:                           43.528343\n",
            "\n",
            "********** Iteration 281 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 161539\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               15.644554661034592\n",
            "Time elapsed:                             99.61 mins\n",
            "KL between old and new distribution:      0.009977729\n",
            "Entropy:                                  0.016151357\n",
            "Surrogate loss:                           41.760468\n",
            "\n",
            "********** Iteration 282 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 162146\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               19.43281878718564\n",
            "Time elapsed:                             99.97 mins\n",
            "KL between old and new distribution:      0.009989758\n",
            "Entropy:                                  0.016597712\n",
            "Surrogate loss:                           42.922443\n",
            "\n",
            "********** Iteration 283 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 162740\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               26.58017664022358\n",
            "Time elapsed:                             100.33 mins\n",
            "KL between old and new distribution:      0.00998479\n",
            "Entropy:                                  0.014169633\n",
            "Surrogate loss:                           45.744823\n",
            "\n",
            "********** Iteration 284 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 163333\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               22.540080928717536\n",
            "Time elapsed:                             100.69 mins\n",
            "KL between old and new distribution:      0.009995427\n",
            "Entropy:                                  0.012842099\n",
            "Surrogate loss:                           44.523674\n",
            "\n",
            "********** Iteration 285 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 163912\n",
            "Average sum of rewards per episode:       -85.35924006908463\n",
            "Std of rewards per episode:               31.12683058313756\n",
            "Time elapsed:                             101.05 mins\n",
            "KL between old and new distribution:      0.0050322046\n",
            "Entropy:                                  0.014652043\n",
            "Surrogate loss:                           48.27123\n",
            "\n",
            "********** Iteration 286 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 164483\n",
            "Average sum of rewards per episode:       -86.57092819614711\n",
            "Std of rewards per episode:               34.630344078746276\n",
            "Time elapsed:                             101.41 mins\n",
            "KL between old and new distribution:      0.009968977\n",
            "Entropy:                                  0.014525481\n",
            "Surrogate loss:                           49.984264\n",
            "\n",
            "********** Iteration 287 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 165079\n",
            "Average sum of rewards per episode:       -82.89765100671141\n",
            "Std of rewards per episode:               31.055394237728716\n",
            "Time elapsed:                             101.78 mins\n",
            "KL between old and new distribution:      0.009999325\n",
            "Entropy:                                  0.014521689\n",
            "Surrogate loss:                           47.1303\n",
            "\n",
            "********** Iteration 288 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 165667\n",
            "Average sum of rewards per episode:       -84.03571428571429\n",
            "Std of rewards per episode:               26.766699600118674\n",
            "Time elapsed:                             102.14 mins\n",
            "KL between old and new distribution:      0.009983586\n",
            "Entropy:                                  0.013411827\n",
            "Surrogate loss:                           46.17971\n",
            "\n",
            "********** Iteration 289 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 166263\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               20.315066176735574\n",
            "Time elapsed:                             102.50 mins\n",
            "KL between old and new distribution:      0.009975108\n",
            "Entropy:                                  0.012840613\n",
            "Surrogate loss:                           43.8774\n",
            "\n",
            "********** Iteration 290 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 166857\n",
            "Average sum of rewards per episode:       -83.17845117845118\n",
            "Std of rewards per episode:               27.28022322891317\n",
            "Time elapsed:                             102.86 mins\n",
            "KL between old and new distribution:      0.009986379\n",
            "Entropy:                                  0.013654138\n",
            "Surrogate loss:                           45.96801\n",
            "\n",
            "********** Iteration 291 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 167447\n",
            "Average sum of rewards per episode:       -83.74915254237288\n",
            "Std of rewards per episode:               28.275846870270186\n",
            "Time elapsed:                             103.22 mins\n",
            "KL between old and new distribution:      0.009998275\n",
            "Entropy:                                  0.013156564\n",
            "Surrogate loss:                           46.516834\n",
            "\n",
            "********** Iteration 292 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 168055\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               19.15185246845618\n",
            "Time elapsed:                             103.58 mins\n",
            "KL between old and new distribution:      0.009982097\n",
            "Entropy:                                  0.013597867\n",
            "Surrogate loss:                           42.804775\n",
            "\n",
            "********** Iteration 293 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 168640\n",
            "Average sum of rewards per episode:       -84.47350427350428\n",
            "Std of rewards per episode:               30.245882373317862\n",
            "Time elapsed:                             103.94 mins\n",
            "KL between old and new distribution:      0.009998128\n",
            "Entropy:                                  0.011869343\n",
            "Surrogate loss:                           47.55162\n",
            "\n",
            "********** Iteration 294 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 169233\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               23.308212849032426\n",
            "Time elapsed:                             104.30 mins\n",
            "KL between old and new distribution:      0.009991434\n",
            "Entropy:                                  0.0143112205\n",
            "Surrogate loss:                           44.68978\n",
            "\n",
            "********** Iteration 295 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 169835\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               20.89051371594481\n",
            "Time elapsed:                             104.66 mins\n",
            "KL between old and new distribution:      0.00999362\n",
            "Entropy:                                  0.015205204\n",
            "Surrogate loss:                           43.580105\n",
            "\n",
            "********** Iteration 296 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 170436\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               19.931781824515646\n",
            "Time elapsed:                             105.02 mins\n",
            "KL between old and new distribution:      0.0062994566\n",
            "Entropy:                                  0.015185537\n",
            "Surrogate loss:                           43.445724\n",
            "\n",
            "********** Iteration 297 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 171032\n",
            "Average sum of rewards per episode:       -82.89597315436242\n",
            "Std of rewards per episode:               27.27444259162491\n",
            "Time elapsed:                             105.38 mins\n",
            "KL between old and new distribution:      0.009980857\n",
            "Entropy:                                  0.014561669\n",
            "Surrogate loss:                           45.83226\n",
            "\n",
            "********** Iteration 298 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 171633\n",
            "Average sum of rewards per episode:       -82.19800332778702\n",
            "Std of rewards per episode:               25.01664795454924\n",
            "Time elapsed:                             105.75 mins\n",
            "KL between old and new distribution:      0.009462657\n",
            "Entropy:                                  0.015337557\n",
            "Surrogate loss:                           44.83274\n",
            "\n",
            "********** Iteration 299 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 172227\n",
            "Average sum of rewards per episode:       -83.17845117845118\n",
            "Std of rewards per episode:               27.09532630114392\n",
            "Time elapsed:                             106.11 mins\n",
            "KL between old and new distribution:      0.009968436\n",
            "Entropy:                                  0.015702283\n",
            "Surrogate loss:                           45.818756\n",
            "\n",
            "********** Iteration 300 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 172828\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               21.31558419783752\n",
            "Time elapsed:                             106.47 mins\n",
            "KL between old and new distribution:      0.00998899\n",
            "Entropy:                                  0.0152328415\n",
            "Surrogate loss:                           43.72685\n",
            "\n",
            "********** Iteration 301 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 173424\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               20.518543773800335\n",
            "Time elapsed:                             106.84 mins\n",
            "KL between old and new distribution:      0.00999494\n",
            "Entropy:                                  0.014935352\n",
            "Surrogate loss:                           43.81926\n",
            "\n",
            "********** Iteration 302 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 174025\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               18.99281026708589\n",
            "Time elapsed:                             107.20 mins\n",
            "KL between old and new distribution:      0.009988369\n",
            "Entropy:                                  0.015615788\n",
            "Surrogate loss:                           43.21591\n",
            "\n",
            "********** Iteration 303 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 174611\n",
            "Average sum of rewards per episode:       -84.32764505119454\n",
            "Std of rewards per episode:               24.899973688260374\n",
            "Time elapsed:                             107.56 mins\n",
            "KL between old and new distribution:      0.00998945\n",
            "Entropy:                                  0.017051535\n",
            "Surrogate loss:                           45.75149\n",
            "\n",
            "********** Iteration 304 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 175191\n",
            "Average sum of rewards per episode:       -85.21034482758621\n",
            "Std of rewards per episode:               28.43080947611765\n",
            "Time elapsed:                             107.93 mins\n",
            "KL between old and new distribution:      0.004761478\n",
            "Entropy:                                  0.014291957\n",
            "Surrogate loss:                           47.26268\n",
            "\n",
            "********** Iteration 305 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 175781\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               21.12342146088806\n",
            "Time elapsed:                             108.29 mins\n",
            "KL between old and new distribution:      0.009967849\n",
            "Entropy:                                  0.016954409\n",
            "Surrogate loss:                           44.416817\n",
            "\n",
            "********** Iteration 306 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 176366\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               21.643805873179307\n",
            "Time elapsed:                             108.65 mins\n",
            "KL between old and new distribution:      0.0099864565\n",
            "Entropy:                                  0.016931871\n",
            "Surrogate loss:                           44.92619\n",
            "\n",
            "********** Iteration 307 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 176912\n",
            "Average sum of rewards per episode:       -90.57875457875458\n",
            "Std of rewards per episode:               37.739591475654485\n",
            "Time elapsed:                             109.01 mins\n",
            "KL between old and new distribution:      0.009984679\n",
            "Entropy:                                  0.02210161\n",
            "Surrogate loss:                           52.95763\n",
            "\n",
            "********** Iteration 308 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 177500\n",
            "Average sum of rewards per episode:       -84.03571428571429\n",
            "Std of rewards per episode:               19.502321944437533\n",
            "Time elapsed:                             109.38 mins\n",
            "KL between old and new distribution:      0.009997651\n",
            "Entropy:                                  0.016598452\n",
            "Surrogate loss:                           44.1911\n",
            "\n",
            "********** Iteration 309 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 178072\n",
            "Average sum of rewards per episode:       -86.41433566433567\n",
            "Std of rewards per episode:               24.820432116157523\n",
            "Time elapsed:                             109.74 mins\n",
            "KL between old and new distribution:      0.009994652\n",
            "Entropy:                                  0.02158633\n",
            "Surrogate loss:                           46.56028\n",
            "\n",
            "********** Iteration 310 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 178653\n",
            "Average sum of rewards per episode:       -85.06196213425129\n",
            "Std of rewards per episode:               27.329435668914833\n",
            "Time elapsed:                             110.10 mins\n",
            "KL between old and new distribution:      0.009978355\n",
            "Entropy:                                  0.016753763\n",
            "Surrogate loss:                           46.796715\n",
            "\n",
            "********** Iteration 311 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 179212\n",
            "Average sum of rewards per episode:       -88.4490161001789\n",
            "Std of rewards per episode:               30.81215222009728\n",
            "Time elapsed:                             110.46 mins\n",
            "KL between old and new distribution:      0.009987108\n",
            "Entropy:                                  0.016970305\n",
            "Surrogate loss:                           49.458355\n",
            "\n",
            "********** Iteration 312 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 179772\n",
            "Average sum of rewards per episode:       -88.28928571428571\n",
            "Std of rewards per episode:               32.86620973502936\n",
            "Time elapsed:                             110.82 mins\n",
            "KL between old and new distribution:      0.009967453\n",
            "Entropy:                                  0.022333408\n",
            "Surrogate loss:                           49.956985\n",
            "\n",
            "********** Iteration 313 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 180359\n",
            "Average sum of rewards per episode:       -84.18057921635435\n",
            "Std of rewards per episode:               20.480882289536858\n",
            "Time elapsed:                             111.18 mins\n",
            "KL between old and new distribution:      0.009982526\n",
            "Entropy:                                  0.016179549\n",
            "Surrogate loss:                           44.45523\n",
            "\n",
            "********** Iteration 314 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 180942\n",
            "Average sum of rewards per episode:       -84.76500857632934\n",
            "Std of rewards per episode:               24.393810415307634\n",
            "Time elapsed:                             111.54 mins\n",
            "KL between old and new distribution:      0.009987373\n",
            "Entropy:                                  0.019493572\n",
            "Surrogate loss:                           45.716396\n",
            "\n",
            "********** Iteration 315 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 181538\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               19.973066621708664\n",
            "Time elapsed:                             111.90 mins\n",
            "KL between old and new distribution:      0.009976806\n",
            "Entropy:                                  0.016138209\n",
            "Surrogate loss:                           43.70753\n",
            "\n",
            "********** Iteration 316 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 182105\n",
            "Average sum of rewards per episode:       -87.18694885361552\n",
            "Std of rewards per episode:               30.39133890537284\n",
            "Time elapsed:                             112.26 mins\n",
            "KL between old and new distribution:      0.0099992445\n",
            "Entropy:                                  0.016308406\n",
            "Surrogate loss:                           48.764584\n",
            "\n",
            "********** Iteration 317 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 182647\n",
            "Average sum of rewards per episode:       -91.25645756457564\n",
            "Std of rewards per episode:               38.815424531326364\n",
            "Time elapsed:                             112.62 mins\n",
            "KL between old and new distribution:      0.009966964\n",
            "Entropy:                                  0.022523668\n",
            "Surrogate loss:                           53.65831\n",
            "\n",
            "********** Iteration 318 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 183231\n",
            "Average sum of rewards per episode:       -84.6181506849315\n",
            "Std of rewards per episode:               18.908750221423894\n",
            "Time elapsed:                             112.98 mins\n",
            "KL between old and new distribution:      0.009969192\n",
            "Entropy:                                  0.018743029\n",
            "Surrogate loss:                           44.280735\n",
            "\n",
            "********** Iteration 319 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 183823\n",
            "Average sum of rewards per episode:       -83.46114864864865\n",
            "Std of rewards per episode:               23.225943178231624\n",
            "Time elapsed:                             113.35 mins\n",
            "KL between old and new distribution:      0.0066710613\n",
            "Entropy:                                  0.014396162\n",
            "Surrogate loss:                           44.91074\n",
            "\n",
            "********** Iteration 320 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 184395\n",
            "Average sum of rewards per episode:       -86.41608391608392\n",
            "Std of rewards per episode:               30.13811366283227\n",
            "Time elapsed:                             113.71 mins\n",
            "KL between old and new distribution:      0.009987872\n",
            "Entropy:                                  0.016572677\n",
            "Surrogate loss:                           48.289677\n",
            "\n",
            "********** Iteration 321 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 185001\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               15.887571194869443\n",
            "Time elapsed:                             114.08 mins\n",
            "KL between old and new distribution:      0.009969748\n",
            "Entropy:                                  0.013915703\n",
            "Surrogate loss:                           42.2366\n",
            "\n",
            "********** Iteration 322 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 185586\n",
            "Average sum of rewards per episode:       -84.47179487179487\n",
            "Std of rewards per episode:               24.72134565444344\n",
            "Time elapsed:                             114.44 mins\n",
            "KL between old and new distribution:      0.009968055\n",
            "Entropy:                                  0.017798213\n",
            "Surrogate loss:                           45.606586\n",
            "\n",
            "********** Iteration 323 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 186176\n",
            "Average sum of rewards per episode:       -83.74915254237288\n",
            "Std of rewards per episode:               27.6225428258003\n",
            "Time elapsed:                             114.81 mins\n",
            "KL between old and new distribution:      0.009973769\n",
            "Entropy:                                  0.014709611\n",
            "Surrogate loss:                           46.3084\n",
            "\n",
            "********** Iteration 324 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 186782\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               19.23861973815016\n",
            "Time elapsed:                             115.18 mins\n",
            "KL between old and new distribution:      0.009996735\n",
            "Entropy:                                  0.015207981\n",
            "Surrogate loss:                           42.92399\n",
            "\n",
            "********** Iteration 325 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 187394\n",
            "Average sum of rewards per episode:       -80.69934640522875\n",
            "Std of rewards per episode:               16.566990160300897\n",
            "Time elapsed:                             115.54 mins\n",
            "KL between old and new distribution:      0.009984273\n",
            "Entropy:                                  0.016041417\n",
            "Surrogate loss:                           42.005047\n",
            "\n",
            "********** Iteration 326 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 187993\n",
            "Average sum of rewards per episode:       -82.47579298831386\n",
            "Std of rewards per episode:               25.725707344233566\n",
            "Time elapsed:                             115.91 mins\n",
            "KL between old and new distribution:      0.009991419\n",
            "Entropy:                                  0.016444393\n",
            "Surrogate loss:                           45.11477\n",
            "\n",
            "********** Iteration 327 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 188582\n",
            "Average sum of rewards per episode:       -83.89134125636673\n",
            "Std of rewards per episode:               21.251227702092713\n",
            "Time elapsed:                             116.27 mins\n",
            "KL between old and new distribution:      0.00997967\n",
            "Entropy:                                  0.017304007\n",
            "Surrogate loss:                           44.50356\n",
            "\n",
            "********** Iteration 328 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 189178\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               15.831979604417002\n",
            "Time elapsed:                             116.63 mins\n",
            "KL between old and new distribution:      0.009983256\n",
            "Entropy:                                  0.0165946\n",
            "Surrogate loss:                           42.838474\n",
            "\n",
            "********** Iteration 329 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 189777\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               13.904236567162647\n",
            "Time elapsed:                             117.00 mins\n",
            "KL between old and new distribution:      0.0011107331\n",
            "Entropy:                                  0.01388038\n",
            "Surrogate loss:                           42.38937\n",
            "\n",
            "********** Iteration 330 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 190381\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               12.303460703343424\n",
            "Time elapsed:                             117.36 mins\n",
            "KL between old and new distribution:      0.00997474\n",
            "Entropy:                                  0.012228756\n",
            "Surrogate loss:                           41.745766\n",
            "\n",
            "********** Iteration 331 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 190980\n",
            "Average sum of rewards per episode:       -82.47412353923205\n",
            "Std of rewards per episode:               17.18675524304702\n",
            "Time elapsed:                             117.72 mins\n",
            "KL between old and new distribution:      0.00998085\n",
            "Entropy:                                  0.017049931\n",
            "Surrogate loss:                           42.966213\n",
            "\n",
            "********** Iteration 332 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 191586\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               14.717439902507719\n",
            "Time elapsed:                             118.09 mins\n",
            "KL between old and new distribution:      0.0099801095\n",
            "Entropy:                                  0.016777875\n",
            "Surrogate loss:                           41.972614\n",
            "\n",
            "********** Iteration 333 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 192169\n",
            "Average sum of rewards per episode:       -84.76500857632934\n",
            "Std of rewards per episode:               21.924586407749402\n",
            "Time elapsed:                             118.45 mins\n",
            "KL between old and new distribution:      0.009978677\n",
            "Entropy:                                  0.012511409\n",
            "Surrogate loss:                           45.067455\n",
            "\n",
            "********** Iteration 334 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 192769\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               12.128455864893382\n",
            "Time elapsed:                             118.82 mins\n",
            "KL between old and new distribution:      0.009993878\n",
            "Entropy:                                  0.010270329\n",
            "Surrogate loss:                           41.95518\n",
            "\n",
            "********** Iteration 335 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 193359\n",
            "Average sum of rewards per episode:       -83.74745762711865\n",
            "Std of rewards per episode:               14.381212507899225\n",
            "Time elapsed:                             119.18 mins\n",
            "KL between old and new distribution:      0.0099716205\n",
            "Entropy:                                  0.013420797\n",
            "Surrogate loss:                           43.02141\n",
            "\n",
            "********** Iteration 336 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 193948\n",
            "Average sum of rewards per episode:       -83.89134125636673\n",
            "Std of rewards per episode:               16.76386717059716\n",
            "Time elapsed:                             119.55 mins\n",
            "KL between old and new distribution:      0.009993807\n",
            "Entropy:                                  0.012627795\n",
            "Surrogate loss:                           43.546585\n",
            "\n",
            "********** Iteration 337 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 194554\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               14.011984532936552\n",
            "Time elapsed:                             119.91 mins\n",
            "KL between old and new distribution:      0.009996148\n",
            "Entropy:                                  0.012150642\n",
            "Surrogate loss:                           41.82548\n",
            "\n",
            "********** Iteration 338 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 195150\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               13.18112977788784\n",
            "Time elapsed:                             120.28 mins\n",
            "KL between old and new distribution:      0.006845227\n",
            "Entropy:                                  0.012278916\n",
            "Surrogate loss:                           42.48318\n",
            "\n",
            "********** Iteration 339 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 195750\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               13.41924395535506\n",
            "Time elapsed:                             120.64 mins\n",
            "KL between old and new distribution:      0.0056055896\n",
            "Entropy:                                  0.012750867\n",
            "Surrogate loss:                           42.248283\n",
            "\n",
            "********** Iteration 340 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 196348\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               15.940722527955195\n",
            "Time elapsed:                             121.00 mins\n",
            "KL between old and new distribution:      0.009402654\n",
            "Entropy:                                  0.012235601\n",
            "Surrogate loss:                           42.77591\n",
            "\n",
            "********** Iteration 341 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 196944\n",
            "Average sum of rewards per episode:       -82.89429530201342\n",
            "Std of rewards per episode:               15.146396375412829\n",
            "Time elapsed:                             121.36 mins\n",
            "KL between old and new distribution:      0.0099716\n",
            "Entropy:                                  0.01258691\n",
            "Surrogate loss:                           42.745\n",
            "\n",
            "********** Iteration 342 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 197539\n",
            "Average sum of rewards per episode:       -83.03529411764706\n",
            "Std of rewards per episode:               19.856724569469673\n",
            "Time elapsed:                             121.72 mins\n",
            "KL between old and new distribution:      0.009981268\n",
            "Entropy:                                  0.014998707\n",
            "Surrogate loss:                           43.744354\n",
            "\n",
            "********** Iteration 343 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 198148\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               18.13380674482031\n",
            "Time elapsed:                             122.09 mins\n",
            "KL between old and new distribution:      0.009992414\n",
            "Entropy:                                  0.015558965\n",
            "Surrogate loss:                           42.41893\n",
            "\n",
            "********** Iteration 344 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 198761\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               17.29470307393601\n",
            "Time elapsed:                             122.45 mins\n",
            "KL between old and new distribution:      0.00997671\n",
            "Entropy:                                  0.015162861\n",
            "Surrogate loss:                           42.040054\n",
            "\n",
            "********** Iteration 345 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 199371\n",
            "Average sum of rewards per episode:       -80.96885245901639\n",
            "Std of rewards per episode:               18.361238939800906\n",
            "Time elapsed:                             122.81 mins\n",
            "KL between old and new distribution:      0.009976427\n",
            "Entropy:                                  0.013939875\n",
            "Surrogate loss:                           42.45877\n",
            "\n",
            "********** Iteration 346 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 199974\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               19.53718990949477\n",
            "Time elapsed:                             123.17 mins\n",
            "KL between old and new distribution:      0.009982553\n",
            "Entropy:                                  0.013825889\n",
            "Surrogate loss:                           43.201675\n",
            "\n",
            "********** Iteration 347 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 200576\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               19.901875782488272\n",
            "Time elapsed:                             123.54 mins\n",
            "KL between old and new distribution:      0.009991811\n",
            "Entropy:                                  0.017952288\n",
            "Surrogate loss:                           43.334396\n",
            "\n",
            "********** Iteration 348 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 201190\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               16.602308134773523\n",
            "Time elapsed:                             123.90 mins\n",
            "KL between old and new distribution:      0.009997745\n",
            "Entropy:                                  0.019109009\n",
            "Surrogate loss:                           41.835808\n",
            "\n",
            "********** Iteration 349 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 201810\n",
            "Average sum of rewards per episode:       -79.64677419354838\n",
            "Std of rewards per episode:               14.04575722578835\n",
            "Time elapsed:                             124.26 mins\n",
            "KL between old and new distribution:      0.009970794\n",
            "Entropy:                                  0.018682487\n",
            "Surrogate loss:                           40.914936\n",
            "\n",
            "********** Iteration 350 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 202418\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               20.44047919730886\n",
            "Time elapsed:                             124.62 mins\n",
            "KL between old and new distribution:      0.0099755395\n",
            "Entropy:                                  0.015431569\n",
            "Surrogate loss:                           43.087955\n",
            "\n",
            "********** Iteration 351 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 203042\n",
            "Average sum of rewards per episode:       -79.1298076923077\n",
            "Std of rewards per episode:               11.655476701641375\n",
            "Time elapsed:                             124.98 mins\n",
            "KL between old and new distribution:      0.009978103\n",
            "Entropy:                                  0.015679717\n",
            "Surrogate loss:                           40.335106\n",
            "\n",
            "********** Iteration 352 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 203643\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               25.331638322023235\n",
            "Time elapsed:                             125.35 mins\n",
            "KL between old and new distribution:      0.0099995565\n",
            "Entropy:                                  0.015844803\n",
            "Surrogate loss:                           44.86813\n",
            "\n",
            "********** Iteration 353 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 204260\n",
            "Average sum of rewards per episode:       -80.03889789303079\n",
            "Std of rewards per episode:               16.284896028397007\n",
            "Time elapsed:                             125.71 mins\n",
            "KL between old and new distribution:      0.0099873915\n",
            "Entropy:                                  0.015840307\n",
            "Surrogate loss:                           41.598694\n",
            "\n",
            "********** Iteration 354 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 204867\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               17.758498382365687\n",
            "Time elapsed:                             126.07 mins\n",
            "KL between old and new distribution:      0.008202399\n",
            "Entropy:                                  0.017228153\n",
            "Surrogate loss:                           42.578476\n",
            "\n",
            "********** Iteration 355 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 205470\n",
            "Average sum of rewards per episode:       -81.92205638474296\n",
            "Std of rewards per episode:               24.623713329353354\n",
            "Time elapsed:                             126.43 mins\n",
            "KL between old and new distribution:      0.009971522\n",
            "Entropy:                                  0.015406756\n",
            "Surrogate loss:                           44.55404\n",
            "\n",
            "********** Iteration 356 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 206071\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               19.20650679862382\n",
            "Time elapsed:                             126.80 mins\n",
            "KL between old and new distribution:      0.009977806\n",
            "Entropy:                                  0.016118065\n",
            "Surrogate loss:                           43.2093\n",
            "\n",
            "********** Iteration 357 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 206687\n",
            "Average sum of rewards per episode:       -80.17045454545455\n",
            "Std of rewards per episode:               17.45118899089646\n",
            "Time elapsed:                             127.16 mins\n",
            "KL between old and new distribution:      0.009996034\n",
            "Entropy:                                  0.015852727\n",
            "Surrogate loss:                           41.91495\n",
            "\n",
            "********** Iteration 358 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 207288\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               20.31723578134915\n",
            "Time elapsed:                             127.52 mins\n",
            "KL between old and new distribution:      0.0099848695\n",
            "Entropy:                                  0.015902406\n",
            "Surrogate loss:                           43.49908\n",
            "\n",
            "********** Iteration 359 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 207900\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               15.334840048082311\n",
            "Time elapsed:                             127.88 mins\n",
            "KL between old and new distribution:      0.009994172\n",
            "Entropy:                                  0.015519994\n",
            "Surrogate loss:                           41.70861\n",
            "\n",
            "********** Iteration 360 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 208509\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               17.656012654472075\n",
            "Time elapsed:                             128.25 mins\n",
            "KL between old and new distribution:      0.007024414\n",
            "Entropy:                                  0.015086985\n",
            "Surrogate loss:                           42.42191\n",
            "\n",
            "********** Iteration 361 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 209116\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               19.412461763407542\n",
            "Time elapsed:                             128.61 mins\n",
            "KL between old and new distribution:      0.009982627\n",
            "Entropy:                                  0.015020994\n",
            "Surrogate loss:                           42.925426\n",
            "\n",
            "********** Iteration 362 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 209730\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               17.14457085111984\n",
            "Time elapsed:                             128.97 mins\n",
            "KL between old and new distribution:      0.009251178\n",
            "Entropy:                                  0.015174075\n",
            "Surrogate loss:                           41.969597\n",
            "\n",
            "********** Iteration 363 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 210351\n",
            "Average sum of rewards per episode:       -79.51690821256038\n",
            "Std of rewards per episode:               16.38737350549637\n",
            "Time elapsed:                             129.34 mins\n",
            "KL between old and new distribution:      0.0099989\n",
            "Entropy:                                  0.017797334\n",
            "Surrogate loss:                           41.303356\n",
            "\n",
            "********** Iteration 364 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 210959\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               20.48083263944828\n",
            "Time elapsed:                             129.70 mins\n",
            "KL between old and new distribution:      0.009574744\n",
            "Entropy:                                  0.016304908\n",
            "Surrogate loss:                           43.10746\n",
            "\n",
            "********** Iteration 365 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 211579\n",
            "Average sum of rewards per episode:       -79.64677419354838\n",
            "Std of rewards per episode:               16.65812034609969\n",
            "Time elapsed:                             130.06 mins\n",
            "KL between old and new distribution:      0.009972507\n",
            "Entropy:                                  0.01798344\n",
            "Surrogate loss:                           41.42775\n",
            "\n",
            "********** Iteration 366 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 212191\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               23.28027157896714\n",
            "Time elapsed:                             130.42 mins\n",
            "KL between old and new distribution:      0.009998475\n",
            "Entropy:                                  0.017571865\n",
            "Surrogate loss:                           43.60136\n",
            "\n",
            "********** Iteration 367 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 212797\n",
            "Average sum of rewards per episode:       -81.51155115511551\n",
            "Std of rewards per episode:               26.507593380668148\n",
            "Time elapsed:                             130.79 mins\n",
            "KL between old and new distribution:      0.009998462\n",
            "Entropy:                                  0.016152527\n",
            "Surrogate loss:                           44.944225\n",
            "\n",
            "********** Iteration 368 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 213407\n",
            "Average sum of rewards per episode:       -80.96885245901639\n",
            "Std of rewards per episode:               20.015912038893543\n",
            "Time elapsed:                             131.15 mins\n",
            "KL between old and new distribution:      0.009971827\n",
            "Entropy:                                  0.01794857\n",
            "Surrogate loss:                           42.855415\n",
            "\n",
            "********** Iteration 369 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 214011\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               23.329861337927575\n",
            "Time elapsed:                             131.51 mins\n",
            "KL between old and new distribution:      0.0099909445\n",
            "Entropy:                                  0.01940246\n",
            "Surrogate loss:                           44.10063\n",
            "\n",
            "********** Iteration 370 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 214623\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               16.64794435737977\n",
            "Time elapsed:                             131.87 mins\n",
            "KL between old and new distribution:      0.00999386\n",
            "Entropy:                                  0.017037803\n",
            "Surrogate loss:                           41.999504\n",
            "\n",
            "********** Iteration 371 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 215218\n",
            "Average sum of rewards per episode:       -83.03697478991597\n",
            "Std of rewards per episode:               30.12944584313642\n",
            "Time elapsed:                             132.23 mins\n",
            "KL between old and new distribution:      0.005820467\n",
            "Entropy:                                  0.01377251\n",
            "Surrogate loss:                           46.8788\n",
            "\n",
            "********** Iteration 372 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 215820\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               22.072703980040526\n",
            "Time elapsed:                             132.59 mins\n",
            "KL between old and new distribution:      0.009992633\n",
            "Entropy:                                  0.014746587\n",
            "Surrogate loss:                           43.906044\n",
            "\n",
            "********** Iteration 373 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 216433\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               17.492503192956093\n",
            "Time elapsed:                             132.95 mins\n",
            "KL between old and new distribution:      0.009971854\n",
            "Entropy:                                  0.015505152\n",
            "Surrogate loss:                           42.05652\n",
            "\n",
            "********** Iteration 374 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 217055\n",
            "Average sum of rewards per episode:       -79.38745980707395\n",
            "Std of rewards per episode:               18.583937597673874\n",
            "Time elapsed:                             133.31 mins\n",
            "KL between old and new distribution:      0.008603447\n",
            "Entropy:                                  0.015117462\n",
            "Surrogate loss:                           41.779007\n",
            "\n",
            "********** Iteration 375 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 217685\n",
            "Average sum of rewards per episode:       -78.36825396825397\n",
            "Std of rewards per episode:               22.461132746434682\n",
            "Time elapsed:                             133.67 mins\n",
            "KL between old and new distribution:      0.004062987\n",
            "Entropy:                                  0.015705695\n",
            "Surrogate loss:                           42.359615\n",
            "\n",
            "********** Iteration 376 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 218314\n",
            "Average sum of rewards per episode:       -78.49284578696343\n",
            "Std of rewards per episode:               15.709364406534704\n",
            "Time elapsed:                             134.03 mins\n",
            "KL between old and new distribution:      0.007094422\n",
            "Entropy:                                  0.01649709\n",
            "Surrogate loss:                           40.78385\n",
            "\n",
            "********** Iteration 377 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 218944\n",
            "Average sum of rewards per episode:       -78.36666666666666\n",
            "Std of rewards per episode:               15.476777278252566\n",
            "Time elapsed:                             134.39 mins\n",
            "KL between old and new distribution:      0.009969441\n",
            "Entropy:                                  0.01978224\n",
            "Surrogate loss:                           40.541763\n",
            "\n",
            "********** Iteration 378 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 219564\n",
            "Average sum of rewards per episode:       -79.64677419354838\n",
            "Std of rewards per episode:               14.328611324807389\n",
            "Time elapsed:                             134.75 mins\n",
            "KL between old and new distribution:      0.0099902805\n",
            "Entropy:                                  0.016461689\n",
            "Surrogate loss:                           41.048527\n",
            "\n",
            "********** Iteration 379 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 220178\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               16.710258125091272\n",
            "Time elapsed:                             135.11 mins\n",
            "KL between old and new distribution:      0.009980388\n",
            "Entropy:                                  0.016362103\n",
            "Surrogate loss:                           41.819305\n",
            "\n",
            "********** Iteration 380 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 220785\n",
            "Average sum of rewards per episode:       -81.37561779242175\n",
            "Std of rewards per episode:               23.776844159671217\n",
            "Time elapsed:                             135.48 mins\n",
            "KL between old and new distribution:      0.007148423\n",
            "Entropy:                                  0.016012775\n",
            "Surrogate loss:                           44.086674\n",
            "\n",
            "********** Iteration 381 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 221390\n",
            "Average sum of rewards per episode:       -81.64628099173554\n",
            "Std of rewards per episode:               20.128443101893588\n",
            "Time elapsed:                             135.84 mins\n",
            "KL between old and new distribution:      0.009989089\n",
            "Entropy:                                  0.015770113\n",
            "Surrogate loss:                           43.210606\n",
            "\n",
            "********** Iteration 382 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 221995\n",
            "Average sum of rewards per episode:       -81.64628099173554\n",
            "Std of rewards per episode:               22.28427545265875\n",
            "Time elapsed:                             136.20 mins\n",
            "KL between old and new distribution:      0.009982155\n",
            "Entropy:                                  0.016558118\n",
            "Surrogate loss:                           43.75552\n",
            "\n",
            "********** Iteration 383 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 222596\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               20.101192916097677\n",
            "Time elapsed:                             136.56 mins\n",
            "KL between old and new distribution:      0.009993008\n",
            "Entropy:                                  0.014900249\n",
            "Surrogate loss:                           43.43914\n",
            "\n",
            "********** Iteration 384 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 223202\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               20.51062031082316\n",
            "Time elapsed:                             136.93 mins\n",
            "KL between old and new distribution:      0.009988465\n",
            "Entropy:                                  0.014186054\n",
            "Surrogate loss:                           43.156494\n",
            "\n",
            "********** Iteration 385 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 223822\n",
            "Average sum of rewards per episode:       -79.64677419354838\n",
            "Std of rewards per episode:               15.16211554034228\n",
            "Time elapsed:                             137.29 mins\n",
            "KL between old and new distribution:      0.009996962\n",
            "Entropy:                                  0.012988627\n",
            "Surrogate loss:                           41.184864\n",
            "\n",
            "********** Iteration 386 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 224421\n",
            "Average sum of rewards per episode:       -82.47579298831386\n",
            "Std of rewards per episode:               27.01515678572827\n",
            "Time elapsed:                             137.65 mins\n",
            "KL between old and new distribution:      0.009993666\n",
            "Entropy:                                  0.01348422\n",
            "Surrogate loss:                           45.532333\n",
            "\n",
            "********** Iteration 387 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 225030\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               18.765359675252096\n",
            "Time elapsed:                             138.01 mins\n",
            "KL between old and new distribution:      0.009616664\n",
            "Entropy:                                  0.013400183\n",
            "Surrogate loss:                           42.666615\n",
            "\n",
            "********** Iteration 388 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 225653\n",
            "Average sum of rewards per episode:       -79.25842696629213\n",
            "Std of rewards per episode:               12.713625181761596\n",
            "Time elapsed:                             138.37 mins\n",
            "KL between old and new distribution:      0.009973296\n",
            "Entropy:                                  0.013979356\n",
            "Surrogate loss:                           40.57798\n",
            "\n",
            "********** Iteration 389 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 226264\n",
            "Average sum of rewards per episode:       -80.83633387888707\n",
            "Std of rewards per episode:               24.458041608548985\n",
            "Time elapsed:                             138.74 mins\n",
            "KL between old and new distribution:      0.009973783\n",
            "Entropy:                                  0.013867002\n",
            "Surrogate loss:                           44.00708\n",
            "\n",
            "********** Iteration 390 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 226872\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               19.954406064690666\n",
            "Time elapsed:                             139.10 mins\n",
            "KL between old and new distribution:      0.0072134514\n",
            "Entropy:                                  0.014473712\n",
            "Surrogate loss:                           42.99948\n",
            "\n",
            "********** Iteration 391 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 227474\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               17.282053618409087\n",
            "Time elapsed:                             139.46 mins\n",
            "KL between old and new distribution:      0.009999631\n",
            "Entropy:                                  0.015655823\n",
            "Surrogate loss:                           42.703304\n",
            "\n",
            "********** Iteration 392 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 228072\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               17.27506020097678\n",
            "Time elapsed:                             139.82 mins\n",
            "KL between old and new distribution:      0.009995858\n",
            "Entropy:                                  0.015261695\n",
            "Surrogate loss:                           43.033886\n",
            "\n",
            "********** Iteration 393 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 228679\n",
            "Average sum of rewards per episode:       -81.37561779242175\n",
            "Std of rewards per episode:               23.356712349306573\n",
            "Time elapsed:                             140.18 mins\n",
            "KL between old and new distribution:      0.0099786455\n",
            "Entropy:                                  0.013982634\n",
            "Surrogate loss:                           43.9415\n",
            "\n",
            "********** Iteration 394 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 229288\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               21.173010159388244\n",
            "Time elapsed:                             140.54 mins\n",
            "KL between old and new distribution:      0.009972868\n",
            "Entropy:                                  0.014989956\n",
            "Surrogate loss:                           43.17472\n",
            "\n",
            "********** Iteration 395 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 229894\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               19.742962174804003\n",
            "Time elapsed:                             140.90 mins\n",
            "KL between old and new distribution:      0.009999762\n",
            "Entropy:                                  0.016360296\n",
            "Surrogate loss:                           43.05335\n",
            "\n",
            "********** Iteration 396 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 230513\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               17.482935795245023\n",
            "Time elapsed:                             141.26 mins\n",
            "KL between old and new distribution:      0.0099760005\n",
            "Entropy:                                  0.017031962\n",
            "Surrogate loss:                           41.742104\n",
            "\n",
            "********** Iteration 397 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 231127\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               14.661817177927514\n",
            "Time elapsed:                             141.62 mins\n",
            "KL between old and new distribution:      0.009995392\n",
            "Entropy:                                  0.01603079\n",
            "Surrogate loss:                           41.46362\n",
            "\n",
            "********** Iteration 398 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 231730\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               16.049786714250484\n",
            "Time elapsed:                             141.98 mins\n",
            "KL between old and new distribution:      0.0069554937\n",
            "Entropy:                                  0.011882524\n",
            "Surrogate loss:                           42.4597\n",
            "\n",
            "********** Iteration 399 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 232324\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               17.957133740615433\n",
            "Time elapsed:                             142.35 mins\n",
            "KL between old and new distribution:      0.009981447\n",
            "Entropy:                                  0.01291867\n",
            "Surrogate loss:                           43.47163\n",
            "\n",
            "********** Iteration 400 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 232921\n",
            "Average sum of rewards per episode:       -82.7537688442211\n",
            "Std of rewards per episode:               19.76744205828884\n",
            "Time elapsed:                             142.71 mins\n",
            "KL between old and new distribution:      0.009974454\n",
            "Entropy:                                  0.0117797265\n",
            "Surrogate loss:                           43.63653\n",
            "\n",
            "********** Iteration 401 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 233528\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               13.445730122837814\n",
            "Time elapsed:                             143.07 mins\n",
            "KL between old and new distribution:      0.007868747\n",
            "Entropy:                                  0.01348876\n",
            "Surrogate loss:                           41.750576\n",
            "\n",
            "********** Iteration 402 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 234129\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               17.449944192577014\n",
            "Time elapsed:                             143.43 mins\n",
            "KL between old and new distribution:      0.009976064\n",
            "Entropy:                                  0.0148800695\n",
            "Surrogate loss:                           42.85072\n",
            "\n",
            "********** Iteration 403 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 234748\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               16.879944521763584\n",
            "Time elapsed:                             143.79 mins\n",
            "KL between old and new distribution:      0.009981376\n",
            "Entropy:                                  0.014629687\n",
            "Surrogate loss:                           41.60385\n",
            "\n",
            "********** Iteration 404 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 235358\n",
            "Average sum of rewards per episode:       -80.9672131147541\n",
            "Std of rewards per episode:               16.399987218222485\n",
            "Time elapsed:                             144.15 mins\n",
            "KL between old and new distribution:      0.0099995965\n",
            "Entropy:                                  0.01622193\n",
            "Surrogate loss:                           41.95742\n",
            "\n",
            "********** Iteration 405 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 235967\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               13.897967551649437\n",
            "Time elapsed:                             144.51 mins\n",
            "KL between old and new distribution:      0.009973351\n",
            "Entropy:                                  0.013922361\n",
            "Surrogate loss:                           41.632256\n",
            "\n",
            "********** Iteration 406 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 236576\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               17.428365360637706\n",
            "Time elapsed:                             144.88 mins\n",
            "KL between old and new distribution:      0.009998173\n",
            "Entropy:                                  0.01464243\n",
            "Surrogate loss:                           42.348465\n",
            "\n",
            "********** Iteration 407 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 237207\n",
            "Average sum of rewards per episode:       -78.24088748019017\n",
            "Std of rewards per episode:               10.857190326218488\n",
            "Time elapsed:                             145.24 mins\n",
            "KL between old and new distribution:      0.008066481\n",
            "Entropy:                                  0.015474118\n",
            "Surrogate loss:                           39.836082\n",
            "\n",
            "********** Iteration 408 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 237823\n",
            "Average sum of rewards per episode:       -80.17045454545455\n",
            "Std of rewards per episode:               15.227234565759508\n",
            "Time elapsed:                             145.60 mins\n",
            "KL between old and new distribution:      0.009992176\n",
            "Entropy:                                  0.015688214\n",
            "Surrogate loss:                           41.44884\n",
            "\n",
            "********** Iteration 409 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 238438\n",
            "Average sum of rewards per episode:       -80.30243902439024\n",
            "Std of rewards per episode:               20.019005049123972\n",
            "Time elapsed:                             145.96 mins\n",
            "KL between old and new distribution:      0.009981233\n",
            "Entropy:                                  0.016265407\n",
            "Surrogate loss:                           42.508236\n",
            "\n",
            "********** Iteration 410 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 239040\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               24.925769035020256\n",
            "Time elapsed:                             146.32 mins\n",
            "KL between old and new distribution:      0.009972856\n",
            "Entropy:                                  0.017468309\n",
            "Surrogate loss:                           44.59241\n",
            "\n",
            "********** Iteration 411 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 239653\n",
            "Average sum of rewards per episode:       -80.56933115823817\n",
            "Std of rewards per episode:               25.05368797765813\n",
            "Time elapsed:                             146.68 mins\n",
            "KL between old and new distribution:      0.009999886\n",
            "Entropy:                                  0.016295295\n",
            "Surrogate loss:                           44.038036\n",
            "\n",
            "********** Iteration 412 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 240277\n",
            "Average sum of rewards per episode:       -79.1298076923077\n",
            "Std of rewards per episode:               19.2430675819376\n",
            "Time elapsed:                             147.04 mins\n",
            "KL between old and new distribution:      0.00998856\n",
            "Entropy:                                  0.017770335\n",
            "Surrogate loss:                           41.788143\n",
            "\n",
            "********** Iteration 413 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 240891\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               18.7412039796588\n",
            "Time elapsed:                             147.40 mins\n",
            "KL between old and new distribution:      0.009993983\n",
            "Entropy:                                  0.017810576\n",
            "Surrogate loss:                           42.300144\n",
            "\n",
            "********** Iteration 414 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 241506\n",
            "Average sum of rewards per episode:       -80.3040650406504\n",
            "Std of rewards per episode:               23.623955729057162\n",
            "Time elapsed:                             147.76 mins\n",
            "KL between old and new distribution:      0.009998941\n",
            "Entropy:                                  0.017222323\n",
            "Surrogate loss:                           43.50567\n",
            "\n",
            "********** Iteration 415 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 242130\n",
            "Average sum of rewards per episode:       -79.1298076923077\n",
            "Std of rewards per episode:               20.279951163496104\n",
            "Time elapsed:                             148.12 mins\n",
            "KL between old and new distribution:      0.009987689\n",
            "Entropy:                                  0.019372674\n",
            "Surrogate loss:                           42.07588\n",
            "\n",
            "********** Iteration 416 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 242759\n",
            "Average sum of rewards per episode:       -78.49284578696343\n",
            "Std of rewards per episode:               16.842826111568957\n",
            "Time elapsed:                             148.48 mins\n",
            "KL between old and new distribution:      0.009979172\n",
            "Entropy:                                  0.021203669\n",
            "Surrogate loss:                           41.005093\n",
            "\n",
            "********** Iteration 417 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 243378\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               18.8021427579961\n",
            "Time elapsed:                             148.84 mins\n",
            "KL between old and new distribution:      0.009989508\n",
            "Entropy:                                  0.015743008\n",
            "Surrogate loss:                           41.99419\n",
            "\n",
            "********** Iteration 418 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 244016\n",
            "Average sum of rewards per episode:       -77.37147335423198\n",
            "Std of rewards per episode:               14.538725760260032\n",
            "Time elapsed:                             149.21 mins\n",
            "KL between old and new distribution:      0.0043123467\n",
            "Entropy:                                  0.014491941\n",
            "Surrogate loss:                           40.023453\n",
            "\n",
            "********** Iteration 419 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 244642\n",
            "Average sum of rewards per episode:       -78.8738019169329\n",
            "Std of rewards per episode:               17.786766374734597\n",
            "Time elapsed:                             149.57 mins\n",
            "KL between old and new distribution:      0.009979687\n",
            "Entropy:                                  0.015471016\n",
            "Surrogate loss:                           41.337074\n",
            "\n",
            "********** Iteration 420 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 245275\n",
            "Average sum of rewards per episode:       -77.99052132701422\n",
            "Std of rewards per episode:               17.822715821509483\n",
            "Time elapsed:                             149.93 mins\n",
            "KL between old and new distribution:      0.009995268\n",
            "Entropy:                                  0.01542468\n",
            "Surrogate loss:                           40.878525\n",
            "\n",
            "********** Iteration 421 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 245897\n",
            "Average sum of rewards per episode:       -79.38745980707395\n",
            "Std of rewards per episode:               18.687204478795305\n",
            "Time elapsed:                             150.29 mins\n",
            "KL between old and new distribution:      0.009995388\n",
            "Entropy:                                  0.01672871\n",
            "Surrogate loss:                           41.72964\n",
            "\n",
            "********** Iteration 422 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 246521\n",
            "Average sum of rewards per episode:       -79.1298076923077\n",
            "Std of rewards per episode:               13.733059819803445\n",
            "Time elapsed:                             150.65 mins\n",
            "KL between old and new distribution:      0.006021743\n",
            "Entropy:                                  0.016417846\n",
            "Surrogate loss:                           40.67334\n",
            "\n",
            "********** Iteration 423 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 247154\n",
            "Average sum of rewards per episode:       -77.99052132701422\n",
            "Std of rewards per episode:               15.072544069277729\n",
            "Time elapsed:                             151.01 mins\n",
            "KL between old and new distribution:      0.00998682\n",
            "Entropy:                                  0.016535936\n",
            "Surrogate loss:                           40.338886\n",
            "\n",
            "********** Iteration 424 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 247781\n",
            "Average sum of rewards per episode:       -78.7464114832536\n",
            "Std of rewards per episode:               17.439468309144107\n",
            "Time elapsed:                             151.37 mins\n",
            "KL between old and new distribution:      0.009983873\n",
            "Entropy:                                  0.017306557\n",
            "Surrogate loss:                           41.182785\n",
            "\n",
            "********** Iteration 425 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 248407\n",
            "Average sum of rewards per episode:       -78.8738019169329\n",
            "Std of rewards per episode:               17.123449084475432\n",
            "Time elapsed:                             151.73 mins\n",
            "KL between old and new distribution:      0.00999213\n",
            "Entropy:                                  0.016808936\n",
            "Surrogate loss:                           41.174015\n",
            "\n",
            "********** Iteration 426 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 249041\n",
            "Average sum of rewards per episode:       -77.86593059936908\n",
            "Std of rewards per episode:               14.89371409025041\n",
            "Time elapsed:                             152.09 mins\n",
            "KL between old and new distribution:      0.001097761\n",
            "Entropy:                                  0.01729303\n",
            "Surrogate loss:                           40.329834\n",
            "\n",
            "********** Iteration 427 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 249671\n",
            "Average sum of rewards per episode:       -78.36666666666666\n",
            "Std of rewards per episode:               17.2046643730843\n",
            "Time elapsed:                             152.45 mins\n",
            "KL between old and new distribution:      0.009978145\n",
            "Entropy:                                  0.01778738\n",
            "Surrogate loss:                           40.878014\n",
            "\n",
            "********** Iteration 428 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 250306\n",
            "Average sum of rewards per episode:       -77.74173228346457\n",
            "Std of rewards per episode:               17.24951872406278\n",
            "Time elapsed:                             152.82 mins\n",
            "KL between old and new distribution:      0.009984422\n",
            "Entropy:                                  0.017127095\n",
            "Surrogate loss:                           40.716686\n",
            "\n",
            "********** Iteration 429 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 250918\n",
            "Average sum of rewards per episode:       -80.70261437908496\n",
            "Std of rewards per episode:               26.120693841469706\n",
            "Time elapsed:                             153.17 mins\n",
            "KL between old and new distribution:      0.009142638\n",
            "Entropy:                                  0.017620228\n",
            "Surrogate loss:                           44.48767\n",
            "\n",
            "********** Iteration 430 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 251539\n",
            "Average sum of rewards per episode:       -79.51690821256038\n",
            "Std of rewards per episode:               16.378232306950334\n",
            "Time elapsed:                             153.53 mins\n",
            "KL between old and new distribution:      0.009982543\n",
            "Entropy:                                  0.018131297\n",
            "Surrogate loss:                           41.302883\n",
            "\n",
            "********** Iteration 431 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 252168\n",
            "Average sum of rewards per episode:       -78.49284578696343\n",
            "Std of rewards per episode:               14.737513526306348\n",
            "Time elapsed:                             153.90 mins\n",
            "KL between old and new distribution:      0.009993011\n",
            "Entropy:                                  0.019248446\n",
            "Surrogate loss:                           40.54321\n",
            "\n",
            "********** Iteration 432 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 252780\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               20.29698935351273\n",
            "Time elapsed:                             154.26 mins\n",
            "KL between old and new distribution:      0.009976964\n",
            "Entropy:                                  0.016655525\n",
            "Surrogate loss:                           42.79941\n",
            "\n",
            "********** Iteration 433 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 253399\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               13.18938932281804\n",
            "Time elapsed:                             154.62 mins\n",
            "KL between old and new distribution:      0.0099947415\n",
            "Entropy:                                  0.01888966\n",
            "Surrogate loss:                           40.79696\n",
            "\n",
            "********** Iteration 434 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 254002\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               18.217598470634826\n",
            "Time elapsed:                             154.98 mins\n",
            "KL between old and new distribution:      0.009975778\n",
            "Entropy:                                  0.020970762\n",
            "Surrogate loss:                           42.87236\n",
            "\n",
            "********** Iteration 435 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 254615\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               15.33946708126812\n",
            "Time elapsed:                             155.34 mins\n",
            "KL between old and new distribution:      0.009971676\n",
            "Entropy:                                  0.021072851\n",
            "Surrogate loss:                           41.662834\n",
            "\n",
            "********** Iteration 436 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 255231\n",
            "Average sum of rewards per episode:       -80.17045454545455\n",
            "Std of rewards per episode:               15.041452586013245\n",
            "Time elapsed:                             155.71 mins\n",
            "KL between old and new distribution:      0.009978758\n",
            "Entropy:                                  0.017481802\n",
            "Surrogate loss:                           41.361126\n",
            "\n",
            "********** Iteration 437 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 255852\n",
            "Average sum of rewards per episode:       -79.51690821256038\n",
            "Std of rewards per episode:               16.074458013405845\n",
            "Time elapsed:                             156.07 mins\n",
            "KL between old and new distribution:      0.009982828\n",
            "Entropy:                                  0.014856053\n",
            "Surrogate loss:                           41.234634\n",
            "\n",
            "********** Iteration 438 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 256474\n",
            "Average sum of rewards per episode:       -79.38745980707395\n",
            "Std of rewards per episode:               15.36572490667292\n",
            "Time elapsed:                             156.43 mins\n",
            "KL between old and new distribution:      0.009982321\n",
            "Entropy:                                  0.0127511155\n",
            "Surrogate loss:                           41.03621\n",
            "\n",
            "********** Iteration 439 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 257096\n",
            "Average sum of rewards per episode:       -79.38906752411576\n",
            "Std of rewards per episode:               23.1532655763184\n",
            "Time elapsed:                             156.80 mins\n",
            "KL between old and new distribution:      0.0099782\n",
            "Entropy:                                  0.014302695\n",
            "Surrogate loss:                           42.89522\n",
            "\n",
            "********** Iteration 440 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 257701\n",
            "Average sum of rewards per episode:       -81.64793388429752\n",
            "Std of rewards per episode:               25.18703621412863\n",
            "Time elapsed:                             157.16 mins\n",
            "KL between old and new distribution:      0.009987067\n",
            "Entropy:                                  0.01480658\n",
            "Surrogate loss:                           44.57811\n",
            "\n",
            "********** Iteration 441 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 258304\n",
            "Average sum of rewards per episode:       -81.92205638474296\n",
            "Std of rewards per episode:               25.044085065466188\n",
            "Time elapsed:                             157.52 mins\n",
            "KL between old and new distribution:      0.009975367\n",
            "Entropy:                                  0.017324468\n",
            "Surrogate loss:                           44.668884\n",
            "\n",
            "********** Iteration 442 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 258906\n",
            "Average sum of rewards per episode:       -82.05813953488372\n",
            "Std of rewards per episode:               17.82001959033152\n",
            "Time elapsed:                             157.88 mins\n",
            "KL between old and new distribution:      0.00999896\n",
            "Entropy:                                  0.015398255\n",
            "Surrogate loss:                           42.85233\n",
            "\n",
            "********** Iteration 443 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 259522\n",
            "Average sum of rewards per episode:       -80.17045454545455\n",
            "Std of rewards per episode:               16.77046638142575\n",
            "Time elapsed:                             158.25 mins\n",
            "KL between old and new distribution:      0.009985746\n",
            "Entropy:                                  0.015000508\n",
            "Surrogate loss:                           41.69152\n",
            "\n",
            "********** Iteration 444 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 260145\n",
            "Average sum of rewards per episode:       -79.25842696629213\n",
            "Std of rewards per episode:               18.740493288526707\n",
            "Time elapsed:                             158.61 mins\n",
            "KL between old and new distribution:      0.009982173\n",
            "Entropy:                                  0.014933737\n",
            "Surrogate loss:                           41.759705\n",
            "\n",
            "********** Iteration 445 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 260786\n",
            "Average sum of rewards per episode:       -77.00468018720748\n",
            "Std of rewards per episode:               16.389419837810873\n",
            "Time elapsed:                             158.98 mins\n",
            "KL between old and new distribution:      0.009995587\n",
            "Entropy:                                  0.016180597\n",
            "Surrogate loss:                           40.123314\n",
            "\n",
            "********** Iteration 446 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 261413\n",
            "Average sum of rewards per episode:       -78.7464114832536\n",
            "Std of rewards per episode:               19.098363675902423\n",
            "Time elapsed:                             159.35 mins\n",
            "KL between old and new distribution:      0.0099930605\n",
            "Entropy:                                  0.019306578\n",
            "Surrogate loss:                           41.544636\n",
            "\n",
            "********** Iteration 447 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 262034\n",
            "Average sum of rewards per episode:       -79.51690821256038\n",
            "Std of rewards per episode:               18.94848820501692\n",
            "Time elapsed:                             159.71 mins\n",
            "KL between old and new distribution:      0.009989463\n",
            "Entropy:                                  0.015336104\n",
            "Surrogate loss:                           41.878445\n",
            "\n",
            "********** Iteration 448 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 262663\n",
            "Average sum of rewards per episode:       -78.49284578696343\n",
            "Std of rewards per episode:               16.10484417965415\n",
            "Time elapsed:                             160.08 mins\n",
            "KL between old and new distribution:      0.009977184\n",
            "Entropy:                                  0.016426684\n",
            "Surrogate loss:                           40.81262\n",
            "\n",
            "********** Iteration 449 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 263282\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               20.000453720571873\n",
            "Time elapsed:                             160.45 mins\n",
            "KL between old and new distribution:      0.009997829\n",
            "Entropy:                                  0.016697267\n",
            "Surrogate loss:                           42.275684\n",
            "\n",
            "********** Iteration 450 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 263912\n",
            "Average sum of rewards per episode:       -78.36825396825397\n",
            "Std of rewards per episode:               21.808858149311025\n",
            "Time elapsed:                             160.81 mins\n",
            "KL between old and new distribution:      0.009984552\n",
            "Entropy:                                  0.016622115\n",
            "Surrogate loss:                           42.124893\n",
            "\n",
            "********** Iteration 451 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 264517\n",
            "Average sum of rewards per episode:       -81.64793388429752\n",
            "Std of rewards per episode:               24.655578213732486\n",
            "Time elapsed:                             161.18 mins\n",
            "KL between old and new distribution:      0.009985125\n",
            "Entropy:                                  0.015208263\n",
            "Surrogate loss:                           44.440674\n",
            "\n",
            "********** Iteration 452 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 265127\n",
            "Average sum of rewards per episode:       -80.96885245901639\n",
            "Std of rewards per episode:               17.127315360850776\n",
            "Time elapsed:                             161.54 mins\n",
            "KL between old and new distribution:      0.009987969\n",
            "Entropy:                                  0.0152715305\n",
            "Surrogate loss:                           42.22905\n",
            "\n",
            "********** Iteration 453 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 265745\n",
            "Average sum of rewards per episode:       -79.90776699029126\n",
            "Std of rewards per episode:               17.4611794438492\n",
            "Time elapsed:                             161.90 mins\n",
            "KL between old and new distribution:      0.0030693992\n",
            "Entropy:                                  0.016045367\n",
            "Surrogate loss:                           41.817444\n",
            "\n",
            "********** Iteration 454 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 266363\n",
            "Average sum of rewards per episode:       -79.90776699029126\n",
            "Std of rewards per episode:               14.569204494725746\n",
            "Time elapsed:                             162.26 mins\n",
            "KL between old and new distribution:      0.00999465\n",
            "Entropy:                                  0.017546132\n",
            "Surrogate loss:                           41.196926\n",
            "\n",
            "********** Iteration 455 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 266976\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               14.910304989247594\n",
            "Time elapsed:                             162.63 mins\n",
            "KL between old and new distribution:      0.009996278\n",
            "Entropy:                                  0.015555329\n",
            "Surrogate loss:                           41.605114\n",
            "\n",
            "********** Iteration 456 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 267587\n",
            "Average sum of rewards per episode:       -80.83469721767594\n",
            "Std of rewards per episode:               15.108245785070602\n",
            "Time elapsed:                             162.99 mins\n",
            "KL between old and new distribution:      0.009977023\n",
            "Entropy:                                  0.017383039\n",
            "Surrogate loss:                           41.658295\n",
            "\n",
            "********** Iteration 457 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 268204\n",
            "Average sum of rewards per episode:       -80.03889789303079\n",
            "Std of rewards per episode:               14.278264156068895\n",
            "Time elapsed:                             163.35 mins\n",
            "KL between old and new distribution:      0.009999521\n",
            "Entropy:                                  0.01823117\n",
            "Surrogate loss:                           41.226215\n",
            "\n",
            "********** Iteration 458 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 268810\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               15.534346094092763\n",
            "Time elapsed:                             163.72 mins\n",
            "KL between old and new distribution:      0.0070831073\n",
            "Entropy:                                  0.016159624\n",
            "Surrogate loss:                           42.188324\n",
            "\n",
            "********** Iteration 459 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 269418\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               18.624775670138547\n",
            "Time elapsed:                             164.08 mins\n",
            "KL between old and new distribution:      0.008079913\n",
            "Entropy:                                  0.016155109\n",
            "Surrogate loss:                           42.68234\n",
            "\n",
            "********** Iteration 460 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 270033\n",
            "Average sum of rewards per episode:       -80.30243902439024\n",
            "Std of rewards per episode:               15.3477704925442\n",
            "Time elapsed:                             164.44 mins\n",
            "KL between old and new distribution:      0.009981204\n",
            "Entropy:                                  0.015083603\n",
            "Surrogate loss:                           41.54527\n",
            "\n",
            "********** Iteration 461 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 270638\n",
            "Average sum of rewards per episode:       -81.64793388429752\n",
            "Std of rewards per episode:               25.392977812329278\n",
            "Time elapsed:                             164.80 mins\n",
            "KL between old and new distribution:      0.009979543\n",
            "Entropy:                                  0.015208915\n",
            "Surrogate loss:                           44.665665\n",
            "\n",
            "********** Iteration 462 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 271245\n",
            "Average sum of rewards per episode:       -81.37397034596376\n",
            "Std of rewards per episode:               15.898882947066573\n",
            "Time elapsed:                             165.16 mins\n",
            "KL between old and new distribution:      0.005867064\n",
            "Entropy:                                  0.015731312\n",
            "Surrogate loss:                           42.16533\n",
            "\n",
            "********** Iteration 463 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 271857\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               17.70372913209593\n",
            "Time elapsed:                             165.52 mins\n",
            "KL between old and new distribution:      0.00997216\n",
            "Entropy:                                  0.018754764\n",
            "Surrogate loss:                           42.165573\n",
            "\n",
            "********** Iteration 464 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 272460\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               18.540806105781964\n",
            "Time elapsed:                             165.88 mins\n",
            "KL between old and new distribution:      0.009993651\n",
            "Entropy:                                  0.018017773\n",
            "Surrogate loss:                           42.940685\n",
            "\n",
            "********** Iteration 465 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 273079\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               16.313529190543296\n",
            "Time elapsed:                             166.24 mins\n",
            "KL between old and new distribution:      0.009974144\n",
            "Entropy:                                  0.015926665\n",
            "Surrogate loss:                           41.453453\n",
            "\n",
            "********** Iteration 466 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 273687\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               19.351425360934705\n",
            "Time elapsed:                             166.60 mins\n",
            "KL between old and new distribution:      0.009966031\n",
            "Entropy:                                  0.01857618\n",
            "Surrogate loss:                           42.83562\n",
            "\n",
            "********** Iteration 467 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 274290\n",
            "Average sum of rewards per episode:       -81.92039800995025\n",
            "Std of rewards per episode:               22.213354830895007\n",
            "Time elapsed:                             166.96 mins\n",
            "KL between old and new distribution:      0.009979724\n",
            "Entropy:                                  0.018059038\n",
            "Surrogate loss:                           43.788216\n",
            "\n",
            "********** Iteration 468 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 274905\n",
            "Average sum of rewards per episode:       -80.30243902439024\n",
            "Std of rewards per episode:               17.449660296339985\n",
            "Time elapsed:                             167.32 mins\n",
            "KL between old and new distribution:      0.009977556\n",
            "Entropy:                                  0.017222548\n",
            "Surrogate loss:                           41.977715\n",
            "\n",
            "********** Iteration 469 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 275519\n",
            "Average sum of rewards per episode:       -80.43485342019544\n",
            "Std of rewards per episode:               19.97836346494557\n",
            "Time elapsed:                             167.68 mins\n",
            "KL between old and new distribution:      0.0099725425\n",
            "Entropy:                                  0.017785298\n",
            "Surrogate loss:                           42.51561\n",
            "\n",
            "********** Iteration 470 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 276119\n",
            "Average sum of rewards per episode:       -82.335\n",
            "Std of rewards per episode:               25.303743629484288\n",
            "Time elapsed:                             168.04 mins\n",
            "KL between old and new distribution:      0.0099909725\n",
            "Entropy:                                  0.022333393\n",
            "Surrogate loss:                           44.85781\n",
            "\n",
            "********** Iteration 471 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 276734\n",
            "Average sum of rewards per episode:       -80.30243902439024\n",
            "Std of rewards per episode:               17.29108733909563\n",
            "Time elapsed:                             168.40 mins\n",
            "KL between old and new distribution:      0.0060857157\n",
            "Entropy:                                  0.022187889\n",
            "Surrogate loss:                           41.95442\n",
            "\n",
            "********** Iteration 472 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 277347\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               21.591507924372447\n",
            "Time elapsed:                             168.75 mins\n",
            "KL between old and new distribution:      0.009399445\n",
            "Entropy:                                  0.017212315\n",
            "Surrogate loss:                           43.10076\n",
            "\n",
            "********** Iteration 473 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 277953\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               19.017858577523533\n",
            "Time elapsed:                             169.11 mins\n",
            "KL between old and new distribution:      0.009992479\n",
            "Entropy:                                  0.017492784\n",
            "Surrogate loss:                           42.86514\n",
            "\n",
            "********** Iteration 474 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 278554\n",
            "Average sum of rewards per episode:       -82.19800332778702\n",
            "Std of rewards per episode:               24.28023571267141\n",
            "Time elapsed:                             169.47 mins\n",
            "KL between old and new distribution:      0.009997037\n",
            "Entropy:                                  0.018869981\n",
            "Surrogate loss:                           44.513454\n",
            "\n",
            "********** Iteration 475 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 279155\n",
            "Average sum of rewards per episode:       -82.19633943427621\n",
            "Std of rewards per episode:               22.402416672982906\n",
            "Time elapsed:                             169.83 mins\n",
            "KL between old and new distribution:      0.009993912\n",
            "Entropy:                                  0.02077353\n",
            "Surrogate loss:                           44.023045\n",
            "\n",
            "********** Iteration 476 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 279774\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               14.275346431847257\n",
            "Time elapsed:                             170.19 mins\n",
            "KL between old and new distribution:      0.009967911\n",
            "Entropy:                                  0.018266931\n",
            "Surrogate loss:                           41.07539\n",
            "\n",
            "********** Iteration 477 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 280379\n",
            "Average sum of rewards per episode:       -81.64628099173554\n",
            "Std of rewards per episode:               21.35850244433924\n",
            "Time elapsed:                             170.55 mins\n",
            "KL between old and new distribution:      0.009970001\n",
            "Entropy:                                  0.020428518\n",
            "Surrogate loss:                           43.465996\n",
            "\n",
            "********** Iteration 478 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 280990\n",
            "Average sum of rewards per episode:       -80.83633387888707\n",
            "Std of rewards per episode:               24.0302466723848\n",
            "Time elapsed:                             170.91 mins\n",
            "KL between old and new distribution:      0.009972719\n",
            "Entropy:                                  0.019854993\n",
            "Surrogate loss:                           43.84703\n",
            "\n",
            "********** Iteration 479 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 281603\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               16.41352049089433\n",
            "Time elapsed:                             171.27 mins\n",
            "KL between old and new distribution:      0.009972875\n",
            "Entropy:                                  0.01720606\n",
            "Surrogate loss:                           41.872437\n",
            "\n",
            "********** Iteration 480 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 282224\n",
            "Average sum of rewards per episode:       -79.51690821256038\n",
            "Std of rewards per episode:               13.02426031006849\n",
            "Time elapsed:                             171.64 mins\n",
            "KL between old and new distribution:      0.009992493\n",
            "Entropy:                                  0.018929427\n",
            "Surrogate loss:                           40.683857\n",
            "\n",
            "********** Iteration 481 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 282836\n",
            "Average sum of rewards per episode:       -80.70098039215686\n",
            "Std of rewards per episode:               14.932214999472288\n",
            "Time elapsed:                             172.00 mins\n",
            "KL between old and new distribution:      0.00999897\n",
            "Entropy:                                  0.017801302\n",
            "Surrogate loss:                           41.682716\n",
            "\n",
            "********** Iteration 482 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 283452\n",
            "Average sum of rewards per episode:       -80.17045454545455\n",
            "Std of rewards per episode:               15.609016618396831\n",
            "Time elapsed:                             172.36 mins\n",
            "KL between old and new distribution:      0.009994141\n",
            "Entropy:                                  0.01663407\n",
            "Surrogate loss:                           41.44597\n",
            "\n",
            "********** Iteration 483 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 284071\n",
            "Average sum of rewards per episode:       -79.77705977382875\n",
            "Std of rewards per episode:               16.504722692647974\n",
            "Time elapsed:                             172.72 mins\n",
            "KL between old and new distribution:      0.009971482\n",
            "Entropy:                                  0.01756151\n",
            "Surrogate loss:                           41.51594\n",
            "\n",
            "********** Iteration 484 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 284675\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               21.25883485015114\n",
            "Time elapsed:                             173.08 mins\n",
            "KL between old and new distribution:      0.009975222\n",
            "Entropy:                                  0.017817656\n",
            "Surrogate loss:                           43.560547\n",
            "\n",
            "********** Iteration 485 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 285269\n",
            "Average sum of rewards per episode:       -83.17676767676768\n",
            "Std of rewards per episode:               23.454750453693084\n",
            "Time elapsed:                             173.44 mins\n",
            "KL between old and new distribution:      0.009986032\n",
            "Entropy:                                  0.017383173\n",
            "Surrogate loss:                           44.818874\n",
            "\n",
            "********** Iteration 486 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 285869\n",
            "Average sum of rewards per episode:       -82.33666666666667\n",
            "Std of rewards per episode:               24.914453413408225\n",
            "Time elapsed:                             173.81 mins\n",
            "KL between old and new distribution:      0.009993199\n",
            "Entropy:                                  0.01778816\n",
            "Surrogate loss:                           44.83996\n",
            "\n",
            "********** Iteration 487 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 286462\n",
            "Average sum of rewards per episode:       -83.31871838111299\n",
            "Std of rewards per episode:               23.6319717347236\n",
            "Time elapsed:                             174.17 mins\n",
            "KL between old and new distribution:      0.009993902\n",
            "Entropy:                                  0.017561136\n",
            "Surrogate loss:                           44.94472\n",
            "\n",
            "********** Iteration 488 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 287075\n",
            "Average sum of rewards per episode:       -80.56769983686786\n",
            "Std of rewards per episode:               20.382094005448337\n",
            "Time elapsed:                             174.53 mins\n",
            "KL between old and new distribution:      0.009990695\n",
            "Entropy:                                  0.017938267\n",
            "Surrogate loss:                           42.785435\n",
            "\n",
            "********** Iteration 489 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 287684\n",
            "Average sum of rewards per episode:       -81.10344827586206\n",
            "Std of rewards per episode:               19.361926767298606\n",
            "Time elapsed:                             174.89 mins\n",
            "KL between old and new distribution:      0.009998712\n",
            "Entropy:                                  0.016420428\n",
            "Surrogate loss:                           42.70402\n",
            "\n",
            "********** Iteration 490 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 288281\n",
            "Average sum of rewards per episode:       -82.75544388609715\n",
            "Std of rewards per episode:               27.06231702991118\n",
            "Time elapsed:                             175.25 mins\n",
            "KL between old and new distribution:      0.00998009\n",
            "Entropy:                                  0.018687237\n",
            "Surrogate loss:                           45.69372\n",
            "\n",
            "********** Iteration 491 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 288889\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               21.576532215515893\n",
            "Time elapsed:                             175.61 mins\n",
            "KL between old and new distribution:      0.0057743266\n",
            "Entropy:                                  0.01780981\n",
            "Surrogate loss:                           43.42971\n",
            "\n",
            "********** Iteration 492 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 289493\n",
            "Average sum of rewards per episode:       -81.78311258278146\n",
            "Std of rewards per episode:               20.403243953395307\n",
            "Time elapsed:                             175.97 mins\n",
            "KL between old and new distribution:      0.009990395\n",
            "Entropy:                                  0.01729011\n",
            "Surrogate loss:                           43.259186\n",
            "\n",
            "********** Iteration 493 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 290101\n",
            "Average sum of rewards per episode:       -81.23848684210526\n",
            "Std of rewards per episode:               18.076974459380367\n",
            "Time elapsed:                             176.33 mins\n",
            "KL between old and new distribution:      0.0040335897\n",
            "Entropy:                                  0.014397068\n",
            "Surrogate loss:                           42.58261\n",
            "\n",
            "********** Iteration 494 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 290707\n",
            "Average sum of rewards per episode:       -81.50990099009901\n",
            "Std of rewards per episode:               17.225616075052717\n",
            "Time elapsed:                             176.69 mins\n",
            "KL between old and new distribution:      0.006931663\n",
            "Entropy:                                  0.013137153\n",
            "Surrogate loss:                           42.52498\n",
            "\n",
            "********** Iteration 495 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 291305\n",
            "Average sum of rewards per episode:       -82.61371237458194\n",
            "Std of rewards per episode:               20.909334762211063\n",
            "Time elapsed:                             177.05 mins\n",
            "KL between old and new distribution:      0.009991027\n",
            "Entropy:                                  0.014216648\n",
            "Surrogate loss:                           43.7882\n",
            "\n",
            "********** Iteration 496 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 291916\n",
            "Average sum of rewards per episode:       -80.83469721767594\n",
            "Std of rewards per episode:               14.442181378762095\n",
            "Time elapsed:                             177.41 mins\n",
            "KL between old and new distribution:      0.009987898\n",
            "Entropy:                                  0.014854667\n",
            "Surrogate loss:                           41.628067\n",
            "\n",
            "********** Iteration 497 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 292531\n",
            "Average sum of rewards per episode:       -80.30243902439024\n",
            "Std of rewards per episode:               16.336190873717843\n",
            "Time elapsed:                             177.77 mins\n",
            "KL between old and new distribution:      0.007043878\n",
            "Entropy:                                  0.01550991\n",
            "Surrogate loss:                           41.77869\n",
            "\n",
            "********** Iteration 498 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 293142\n",
            "Average sum of rewards per episode:       -80.83469721767594\n",
            "Std of rewards per episode:               17.9504821894298\n",
            "Time elapsed:                             178.13 mins\n",
            "KL between old and new distribution:      0.006248064\n",
            "Entropy:                                  0.0152933225\n",
            "Surrogate loss:                           42.36464\n",
            "\n",
            "********** Iteration 499 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 293762\n",
            "Average sum of rewards per episode:       -79.64677419354838\n",
            "Std of rewards per episode:               13.790695995698899\n",
            "Time elapsed:                             178.49 mins\n",
            "KL between old and new distribution:      0.009968147\n",
            "Entropy:                                  0.014971586\n",
            "Surrogate loss:                           40.90077\n",
            "\n",
            "********** Iteration 500 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 294387\n",
            "Average sum of rewards per episode:       -79.0016\n",
            "Std of rewards per episode:               15.355988976291952\n",
            "Time elapsed:                             178.85 mins\n",
            "KL between old and new distribution:      0.0099983355\n",
            "Entropy:                                  0.013759842\n",
            "Surrogate loss:                           40.9284\n",
            "\n",
            "********** Iteration 501 ************\n",
            "Rollout\n",
            "Made rollout\n",
            "Total number of episodes:                 295004\n",
            "Average sum of rewards per episode:       -80.03889789303079\n",
            "Std of rewards per episode:               21.569797993844237\n",
            "Time elapsed:                             179.21 mins\n",
            "KL between old and new distribution:      0.009995152\n",
            "Entropy:                                  0.0145819755\n",
            "Surrogate loss:                           42.807377\n",
            "\n",
            "********** Iteration 502 ************\n",
            "Rollout\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEwMeYikkytM"
      },
      "source": [
        "# Homework option I: better sampling (10+pts)\n",
        "\n",
        "In this section, you're invited to implement a better rollout strategy called _vine_.\n",
        "\n",
        "![img](https://s17.postimg.cc/i90chxgvj/vine.png)\n",
        "\n",
        "In most gym environments, you can actually backtrack by using states. You can find a wrapper that saves/loads states in [the mcts seminar](https://github.com/yandexdataschool/Practical_RL/blob/master/week10_planning/seminar_MCTS.ipynb).\n",
        "\n",
        "You can read more about in the [TRPO article](https://arxiv.org/abs/1502.05477) in section 5.2.\n",
        "\n",
        "The goal here is to implement such rollout policy (we recommend using tree data structure like in the seminar above).\n",
        "Then you can assign cummulative rewards similar to `get_cummulative_rewards`, but for a tree.\n",
        "\n",
        "__bonus task__ - parallelize samples using multiple cores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eCCUtJjkytM"
      },
      "source": [
        "# Homework option II (10+pts)\n",
        "\n",
        "Let's use TRPO to train evil robots! (pick any of two)\n",
        "* [MuJoCo robots](https://gym.openai.com/envs#mujoco)\n",
        "* [Box2d robot](https://gym.openai.com/envs/BipedalWalker-v2)\n",
        "\n",
        "The catch here is that those environments have continuous action spaces. \n",
        "\n",
        "Luckily, TRPO is a policy gradient method, so it's gonna work for any parametric $\\pi_\\theta(a|s)$. We recommend starting with gaussian policy:\n",
        "\n",
        "$$\\pi_\\theta(a|s) = N(\\mu_\\theta(s),\\sigma^2_\\theta(s)) = {1 \\over \\sqrt { 2 \\pi {\\sigma^2}_\\theta(s) } } e^{ (a - \n",
        "\\mu_\\theta(s))^2 \\over 2 {\\sigma^2}_\\theta(s) } $$\n",
        "\n",
        "In the $\\sqrt { 2 \\pi {\\sigma^2}_\\theta(s) }$ clause, $\\pi$ means ~3.1415926, not agent's policy.\n",
        "\n",
        "This essentially means that you will need two output layers:\n",
        "* $\\mu_\\theta(s)$, a dense layer with linear activation\n",
        "* ${\\sigma^2}_\\theta(s)$, a dense layer with activation tf.exp (to make it positive; like rho from bandits)\n",
        "\n",
        "For multidimensional actions, you can use fully factorized gaussian (basically a vector of gaussians).\n",
        "\n",
        "__bonus task__: compare performance of continuous action space method to action space discretization"
      ]
    }
  ]
}